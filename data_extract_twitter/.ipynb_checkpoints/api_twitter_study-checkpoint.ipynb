{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/julio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from api_keys import BEARER_TOKEN\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun√ß√µes (An√°lise Explorat√≥ria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para plotar bar plot com a contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_count_words(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para plotar bar plot com tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_tf_idf(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    \"MAX\":data_vect.std(axis=0)\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text):\n",
    "\n",
    "    quantity_of_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_words = [i for i in quantity_of_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_words = len(quantity_of_words)\n",
    "\n",
    "    return quantity_of_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para contagem de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_diferent_words(text):\n",
    "\n",
    "    quantity_of_diferent_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_diferent_words = [i for i in quantity_of_diferent_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_diferent_words = set(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = list(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = len(quantity_of_diferent_words)\n",
    "\n",
    "    return quantity_of_diferent_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para criar textos sem repeti√ß√£o de palavras para ser utilizado na an√°lise explorat√≥ria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_no_repeat_words(text):\n",
    "\n",
    "    text_with_no_repeat_words = text.split(\" \")\n",
    "\n",
    "    text_with_no_repeat_words = [i for i in text_with_no_repeat_words if i!=\"\"]\n",
    "\n",
    "    text_with_no_repeat_words = set(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = list(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = \" \".join(text_with_no_repeat_words)\n",
    "\n",
    "    return text_with_no_repeat_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para o pr√©-processamento do texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "    collection_text = [ {\"text\" : text}]\n",
    "    text = pd.DataFrame(collection_text)\n",
    "\n",
    "    text['text'] = text['text'].astype('str')\n",
    "    text['text'] = text['text'].str.lower()\n",
    "    text['text'] = text['text'].str.replace('\\n',' ')\n",
    "    text['text'] = text['text'].str.replace('\\r',' ')\n",
    "    text['text'] = text['text'].apply(lambda x: norm('NFKD', x).encode('ascii', 'ignore').decode())\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(nltk_stopwords))\n",
    "    text['text'] = text['text'].str.replace(pat,'')\n",
    "    text = text['text'].values[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para limpeza dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text,stop_words_domain =None):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "    regex_stop_words = '|'.join(nltk_stopwords)\n",
    "    text = re.sub(r\"\\shttps([a-zA-Z√†-√∫√Ä-√ö0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+$|^https([a-zA-Z√†-√∫√Ä-√ö0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s|\\shttps([a-zA-Z√†-√∫√Ä-√ö0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s\",\" \",text)\n",
    "    text = re.sub(r\"[^a-zA-Z√Ä-√ö√†-√∫]+\",\" \",text)\n",
    "    text = re.sub(r\"\\s({})\\s|\\s({})$|^({})\\s\".format(regex_stop_words,regex_stop_words,regex_stop_words),\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \" uhahua,n√£o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' uhahua '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " '√©',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'n√£o',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " '√†',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'j√°',\n",
       " 'eu',\n",
       " 'tamb√©m',\n",
       " 's√≥',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'at√©',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'voc√™',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " '√†s',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'n√≥s',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'voc√™s',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo',\n",
       " 'estou',\n",
       " 'est√°',\n",
       " 'estamos',\n",
       " 'est√£o',\n",
       " 'estive',\n",
       " 'esteve',\n",
       " 'estivemos',\n",
       " 'estiveram',\n",
       " 'estava',\n",
       " 'est√°vamos',\n",
       " 'estavam',\n",
       " 'estivera',\n",
       " 'estiv√©ramos',\n",
       " 'esteja',\n",
       " 'estejamos',\n",
       " 'estejam',\n",
       " 'estivesse',\n",
       " 'estiv√©ssemos',\n",
       " 'estivessem',\n",
       " 'estiver',\n",
       " 'estivermos',\n",
       " 'estiverem',\n",
       " 'hei',\n",
       " 'h√°',\n",
       " 'havemos',\n",
       " 'h√£o',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houveram',\n",
       " 'houvera',\n",
       " 'houv√©ramos',\n",
       " 'haja',\n",
       " 'hajamos',\n",
       " 'hajam',\n",
       " 'houvesse',\n",
       " 'houv√©ssemos',\n",
       " 'houvessem',\n",
       " 'houver',\n",
       " 'houvermos',\n",
       " 'houverem',\n",
       " 'houverei',\n",
       " 'houver√°',\n",
       " 'houveremos',\n",
       " 'houver√£o',\n",
       " 'houveria',\n",
       " 'houver√≠amos',\n",
       " 'houveriam',\n",
       " 'sou',\n",
       " 'somos',\n",
       " 's√£o',\n",
       " 'era',\n",
       " '√©ramos',\n",
       " 'eram',\n",
       " 'fui',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'foram',\n",
       " 'fora',\n",
       " 'f√¥ramos',\n",
       " 'seja',\n",
       " 'sejamos',\n",
       " 'sejam',\n",
       " 'fosse',\n",
       " 'f√¥ssemos',\n",
       " 'fossem',\n",
       " 'for',\n",
       " 'formos',\n",
       " 'forem',\n",
       " 'serei',\n",
       " 'ser√°',\n",
       " 'seremos',\n",
       " 'ser√£o',\n",
       " 'seria',\n",
       " 'ser√≠amos',\n",
       " 'seriam',\n",
       " 'tenho',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 't√©m',\n",
       " 'tinha',\n",
       " 't√≠nhamos',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'teve',\n",
       " 'tivemos',\n",
       " 'tiveram',\n",
       " 'tivera',\n",
       " 'tiv√©ramos',\n",
       " 'tenha',\n",
       " 'tenhamos',\n",
       " 'tenham',\n",
       " 'tivesse',\n",
       " 'tiv√©ssemos',\n",
       " 'tivessem',\n",
       " 'tiver',\n",
       " 'tivermos',\n",
       " 'tiverem',\n",
       " 'terei',\n",
       " 'ter√°',\n",
       " 'teremos',\n",
       " 'ter√£o',\n",
       " 'teria',\n",
       " 'ter√≠amos',\n",
       " 'teriam']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun√ß√µes (Extra√ß√£o de Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def create_url(query = \"@globoplay -is:retweet\",until_id=None):\n",
    "    \n",
    "    #query = \"@BBB -is:retweet\"\n",
    "    #\"from:twitterdev -is:retweet\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    \n",
    "    if until_id:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100&until_id={}\".format(\n",
    "            query,until_id\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100\".format(\n",
    "            query\n",
    "        )\n",
    "            \n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def extract_100_tweets(query = \"@BBB -is:retweet\",until_id=None):\n",
    "    bearer_token = BEARER_TOKEN\n",
    "    url = create_url(query,until_id)\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    data_tweets = json.dumps(json_response, indent=4, sort_keys=True)\n",
    "    return json_response\n",
    "\n",
    "def extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",start_from_id=None,query=\"@BBB\"):\n",
    "    \n",
    "    \n",
    "    oldest_id = None\n",
    "    \n",
    "    for i in tqdm(range(qnt_cycle)):\n",
    "    \n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            #extract the 100 tweets first\n",
    "            \n",
    "            if start_from_id:\n",
    "        \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=None)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=start_from_id)\n",
    "                \n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets[\"data\"])\n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            \n",
    "            oldest_id = data_tweets['meta']['oldest_id']\n",
    "            \n",
    "            oldest_date = date_extraction\n",
    "            \n",
    "            df_data_tweets = df_data_tweets_temp.copy()\n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,date_extraction_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file,sep=\",\")\n",
    "            \n",
    "    \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            #extract more 100 tweets older\n",
    "            \n",
    "            data_tweets_temp = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=oldest_id)\n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets_temp[\"data\"])\n",
    "            \n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            oldest_id = data_tweets_temp['meta']['oldest_id']\n",
    "            \n",
    "            df_data_tweets = pd.concat([df_data_tweets,df_data_tweets_temp.copy()])\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets.reset_index(inplace=True,drop=True)\n",
    "            \n",
    "            \n",
    "            # remove old files\n",
    "            \n",
    "            os.remove(name_file)\n",
    "            \n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            oldest_date_str = str(oldest_date).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,oldest_date_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file.format(folder),sep=\",\")\n",
    "            \n",
    "            \n",
    "\n",
    "    return df_data_tweets\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra√ß√£o de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:14<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "data_tweets_final = extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",query=\"globoplay\")#,start_from_id=\"1367600965277384706\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date_extraction</th>\n",
       "      <th>text_unique_words</th>\n",
       "      <th>number_tokens</th>\n",
       "      <th>number_diferent_tokens</th>\n",
       "      <th>bins</th>\n",
       "      <th>indices_bins</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1383949586826334212</td>\n",
       "      <td>@globoplay @rafakalimann_ ningu√©m pediu isso c...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>usurpadora logo a no pediu coloca cat√°logo @gl...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y @r f k lim nn_ ningu m p diu   c l ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1383949548708499457</td>\n",
       "      <td>@hallentlynn amiga no rave n√£o tem globoplay ü•∫</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@hallentlynn no rave tem n√£o amiga globoplay ü•∫</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@h ll ntlynn  mig    r v     m gl b pl y ü•∫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1383949443326611459</td>\n",
       "      <td>@evansftx amg mas no rave tem a op√ß√£o globopla...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>a pq mas no antes op√ß√£o tinha amg rave tem n√£o...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@ v nsftx  mg     r v   m    p√ß√£  gl b pl y? p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1383949414197186561</td>\n",
       "      <td>Melhor pessoa desse bbb https://t.co/HaKu8sRLkX</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>desse bbb Melhor pessoa https://t.co/HaKu8sRLkX</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>M lh r p ss    s  bbb https://t.c /H Ku8sRLkX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1383949406836191237</td>\n",
       "      <td>@globoplay Eu gostei, mas de fato achei que el...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>gostei, tendo mas üòÖüòÖüòÖüòÖ ele estava fato convuls...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y Eu g s i,     f t   c     l   st v ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1383949316419555335</td>\n",
       "      <td>Nossa, como deve ser horr√≠vel ser hater do Gil...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como ser ü§≠‚úåüèª Gil horr√≠vel hater vigor Nossa, h...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>N ss ,     v   r h rr√≠v l  r h  r   Gil   vig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383949242562084877</td>\n",
       "      <td>n√£o faz sentido algum minha globoplay n√£o func...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>algum faz sentido na minha n√£o funcionar tv gl...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>f z  nti   lg    gl b pl y   funci  r   tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1383949219149451273</td>\n",
       "      <td>Estou aguardando pelos pr√≥ximos epis√≥dios da s...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>da A epis√≥dios aguardando vacinas pelos das s√©...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>Est u  gu r n   s pr√≥xim s  pi di s   s ri  A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1383949162064998402</td>\n",
       "      <td>@globoplay quando poderei matar as saudades de...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>quando matar UM NO @globoplay as de O.C. poder...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y   p  r i m t r  s s u  s   O.C. UM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1383949094515666946</td>\n",
       "      <td>@hallentlynn se essa pessoa tbm tiver a globop...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>tiver a @hallentlynn tbm globoplay, sim se pes...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@h ll ntlynn    ss  p ss   tbm  r   gl b pl y,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1383949002995994632</td>\n",
       "      <td>@cadu_monteiroo Globoplay</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@cadu_monteiroo Globoplay</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>@c du_m n ir   Gl b pl y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1383948991755259913</td>\n",
       "      <td>Fala s√©rio esse QR code a√≠ do Deezer √© a maior...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>a aparece maior Deezer Globo do sacanagem!. QR...</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>[25.9,32.1)</td>\n",
       "      <td>4</td>\n",
       "      <td>F l  s ri   s  QR c    √≠   D  z r     m i r fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1383948908703805445</td>\n",
       "      <td>gente, voc√™s sabem me dizer se tem como assist...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como tipo com mesmo s√©rie me assistir rave? di...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>g n ,  s s b m   diz r    m     ssistir    s r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1383948838000492546</td>\n",
       "      <td>O GIL &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; üó£üó£üó£üó£ https://t.co/v...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; https://t.co/vitHOewEwT üó£...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>O GIL &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; üó£üó£üó£üó£ https://t.c /v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1383948765199953927</td>\n",
       "      <td>@globoplay Nunca tive tanta curtida na minha v...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>tive na minha vida. Nunca @globoplay curtida t...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y Nunc    t nt  curti      vi .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1383948707838664707</td>\n",
       "      <td>@annavoig_ Gi o globoplay funciona a√≠? √â s√≥ se...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>√â o Gi funciona a√≠? d√° s√≥ cadastrar que viva√ßo...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>@ n v ig_ Gi   gl b pl y funci    √≠? √â     c  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1383948670064726016</td>\n",
       "      <td>1 Contra todos, tem no Globoplay</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>no Contra tem todos, 1 Globoplay</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>1 C ntr  t  s,  m   Gl b pl y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1383948621293391872</td>\n",
       "      <td>@rafakalimann_ @globoplay Parabens Rafa K üëèüèªüëèüèª</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>Rafa K @globoplay Parabens @rafakalimann_ üëèüèªüëèüèª</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>@r f k lim nn_ @gl b pl y P r b ns R f  K üëèüèªüëèüèª</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1383948574707253259</td>\n",
       "      <td>@globoplay agora por exemplo, estou tentando p...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>exemplo, por a estou canais. anuncio, agora qu...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>@gl b pl y  g r     x mpl ,  st u  nt n  pul r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1383948502904958980</td>\n",
       "      <td>@joicemara Cancelei a Netflix pra assinar a Gl...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>a Cancelei e @joicemara melhor foi assinar Net...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@j ic m r  C nc l i   N tflix pr   ssi r   Gl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1383948348810428420</td>\n",
       "      <td>@Mathcarvalhop Claro! Mas me segue l√° no insta...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@Mathcarvalhop https://t.co/5cjNxV9Sb2 no http...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>@M thc rv lh p Cl r ! M s    gu  l√°   inst   n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1383948298428444675</td>\n",
       "      <td>e agora a globoplay bugou e eu nao sei aonde e...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>s√©rie, a vou bugou eu agora nao chorar errado ...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>g r    gl b pl y bug u    u     i   n   u p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1383948265977090058</td>\n",
       "      <td>gente, tem como ver bbb na globoplay pela tv? ...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como por a ver nem ppv bbb estamos pra apenas ...</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>g n ,  m    v r bbb   gl b pl y   tv? n c nsig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1383948224981995526</td>\n",
       "      <td>@globoplay @rafakalimann_ Ela precisa de ajuda...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como tudoo....fotos a Deus...me inje√ß√£o que m√©...</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>@gl b pl y @r f k lim nn_ El  pr cis     ju  U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1383948192635494403</td>\n",
       "      <td>@globoplay @rafakalimann_ Ela precisa de ajuda...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como tudoo....fotos a Deus...me https://t.co/v...</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>@gl b pl y @r f k lim nn_ El  pr cis     ju  U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1383948098607583232</td>\n",
       "      <td>@vagner_a @globoplay J√° estiu na 6 temporada!\\...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>6 J√° ‚ù§ @vagner_a temporada!\\nQue na estiu boa ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@v gn r_  @gl b pl y J√°  stiu   6  m   !\\nQu  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1383948096611127296</td>\n",
       "      <td>@jarcysdion @vanessadamata @robertocarlos @sho...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@jarcysdion Meu @showdavida @vanessadamata @ro...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@j rcysdi n @v n ss  m t  @r b rt c rl s @sh w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1383948083189338117</td>\n",
       "      <td>Caio est√° cozinhando e choca quem achou que s√≥...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>#TeamGil choca que cuca #BBB21 mestre https://...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>C i   st√° c zinh n    ch c   m  ch u       Fiu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1383947959872593940</td>\n",
       "      <td>tvd vai estar na globoplay s√≥ at√© dia 30 q por...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>q 30 tvd dia na essa??? vou vai assistir? esta...</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>tvd v i  st r   gl b pl y    t  di  30 q  r   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1383947864653524996</td>\n",
       "      <td>@globoplay PELO AMOR D DEUS T√î SEM SINAL DO CA...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>ver bbb!!!! SINAL PELO AMOR SEM CANAL T√î DO DI...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>@gl b pl y PELO AMOR D DEUS T√î SEM SINAL DO CA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1383949586826334212  @globoplay @rafakalimann_ ningu√©m pediu isso c...   \n",
       "1   1383949548708499457     @hallentlynn amiga no rave n√£o tem globoplay ü•∫   \n",
       "2   1383949443326611459  @evansftx amg mas no rave tem a op√ß√£o globopla...   \n",
       "3   1383949414197186561    Melhor pessoa desse bbb https://t.co/HaKu8sRLkX   \n",
       "4   1383949406836191237  @globoplay Eu gostei, mas de fato achei que el...   \n",
       "5   1383949316419555335  Nossa, como deve ser horr√≠vel ser hater do Gil...   \n",
       "6   1383949242562084877  n√£o faz sentido algum minha globoplay n√£o func...   \n",
       "7   1383949219149451273  Estou aguardando pelos pr√≥ximos epis√≥dios da s...   \n",
       "8   1383949162064998402  @globoplay quando poderei matar as saudades de...   \n",
       "9   1383949094515666946  @hallentlynn se essa pessoa tbm tiver a globop...   \n",
       "10  1383949002995994632                          @cadu_monteiroo Globoplay   \n",
       "11  1383948991755259913  Fala s√©rio esse QR code a√≠ do Deezer √© a maior...   \n",
       "12  1383948908703805445  gente, voc√™s sabem me dizer se tem como assist...   \n",
       "13  1383948838000492546  O GIL &gt;&gt;&gt;&gt;&gt; üó£üó£üó£üó£ https://t.co/v...   \n",
       "14  1383948765199953927  @globoplay Nunca tive tanta curtida na minha v...   \n",
       "15  1383948707838664707  @annavoig_ Gi o globoplay funciona a√≠? √â s√≥ se...   \n",
       "16  1383948670064726016                   1 Contra todos, tem no Globoplay   \n",
       "17  1383948621293391872     @rafakalimann_ @globoplay Parabens Rafa K üëèüèªüëèüèª   \n",
       "18  1383948574707253259  @globoplay agora por exemplo, estou tentando p...   \n",
       "19  1383948502904958980  @joicemara Cancelei a Netflix pra assinar a Gl...   \n",
       "20  1383948348810428420  @Mathcarvalhop Claro! Mas me segue l√° no insta...   \n",
       "21  1383948298428444675  e agora a globoplay bugou e eu nao sei aonde e...   \n",
       "22  1383948265977090058  gente, tem como ver bbb na globoplay pela tv? ...   \n",
       "23  1383948224981995526  @globoplay @rafakalimann_ Ela precisa de ajuda...   \n",
       "24  1383948192635494403  @globoplay @rafakalimann_ Ela precisa de ajuda...   \n",
       "25  1383948098607583232  @vagner_a @globoplay J√° estiu na 6 temporada!\\...   \n",
       "26  1383948096611127296  @jarcysdion @vanessadamata @robertocarlos @sho...   \n",
       "27  1383948083189338117  Caio est√° cozinhando e choca quem achou que s√≥...   \n",
       "28  1383947959872593940  tvd vai estar na globoplay s√≥ at√© dia 30 q por...   \n",
       "29  1383947864653524996  @globoplay PELO AMOR D DEUS T√î SEM SINAL DO CA...   \n",
       "\n",
       "              date_extraction  \\\n",
       "0  2021-04-18 22:04:46.634032   \n",
       "1  2021-04-18 22:04:46.634032   \n",
       "2  2021-04-18 22:04:46.634032   \n",
       "3  2021-04-18 22:04:46.634032   \n",
       "4  2021-04-18 22:04:46.634032   \n",
       "5  2021-04-18 22:04:46.634032   \n",
       "6  2021-04-18 22:04:46.634032   \n",
       "7  2021-04-18 22:04:46.634032   \n",
       "8  2021-04-18 22:04:46.634032   \n",
       "9  2021-04-18 22:04:46.634032   \n",
       "10 2021-04-18 22:04:46.634032   \n",
       "11 2021-04-18 22:04:46.634032   \n",
       "12 2021-04-18 22:04:46.634032   \n",
       "13 2021-04-18 22:04:46.634032   \n",
       "14 2021-04-18 22:04:46.634032   \n",
       "15 2021-04-18 22:04:46.634032   \n",
       "16 2021-04-18 22:04:46.634032   \n",
       "17 2021-04-18 22:04:46.634032   \n",
       "18 2021-04-18 22:04:46.634032   \n",
       "19 2021-04-18 22:04:46.634032   \n",
       "20 2021-04-18 22:04:46.634032   \n",
       "21 2021-04-18 22:04:46.634032   \n",
       "22 2021-04-18 22:04:46.634032   \n",
       "23 2021-04-18 22:04:46.634032   \n",
       "24 2021-04-18 22:04:46.634032   \n",
       "25 2021-04-18 22:04:46.634032   \n",
       "26 2021-04-18 22:04:46.634032   \n",
       "27 2021-04-18 22:04:46.634032   \n",
       "28 2021-04-18 22:04:46.634032   \n",
       "29 2021-04-18 22:04:46.634032   \n",
       "\n",
       "                                    text_unique_words  number_tokens  \\\n",
       "0   usurpadora logo a no pediu coloca cat√°logo @gl...             11   \n",
       "1      @hallentlynn no rave tem n√£o amiga globoplay ü•∫              8   \n",
       "2   a pq mas no antes op√ß√£o tinha amg rave tem n√£o...             13   \n",
       "3     desse bbb Melhor pessoa https://t.co/HaKu8sRLkX              5   \n",
       "4   gostei, tendo mas üòÖüòÖüòÖüòÖ ele estava fato convuls...             13   \n",
       "5   como ser ü§≠‚úåüèª Gil horr√≠vel hater vigor Nossa, h...             13   \n",
       "6   algum faz sentido na minha n√£o funcionar tv gl...             10   \n",
       "7   da A epis√≥dios aguardando vacinas pelos das s√©...             14   \n",
       "8   quando matar UM NO @globoplay as de O.C. poder...             12   \n",
       "9   tiver a @hallentlynn tbm globoplay, sim se pes...              9   \n",
       "10                          @cadu_monteiroo Globoplay              2   \n",
       "11  a aparece maior Deezer Globo do sacanagem!. QR...             31   \n",
       "12  como tipo com mesmo s√©rie me assistir rave? di...             21   \n",
       "13  &gt;&gt;&gt;&gt;&gt; https://t.co/vitHOewEwT üó£...              5   \n",
       "14  tive na minha vida. Nunca @globoplay curtida t...              8   \n",
       "15  √â o Gi funciona a√≠? d√° s√≥ cadastrar que viva√ßo...             16   \n",
       "16                   no Contra tem todos, 1 Globoplay              6   \n",
       "17     Rafa K @globoplay Parabens @rafakalimann_ üëèüèªüëèüèª              6   \n",
       "18  exemplo, por a estou canais. anuncio, agora qu...             23   \n",
       "19  a Cancelei e @joicemara melhor foi assinar Net...             13   \n",
       "20  @Mathcarvalhop https://t.co/5cjNxV9Sb2 no http...             15   \n",
       "21  s√©rie, a vou bugou eu agora nao chorar errado ...             21   \n",
       "22  como por a ver nem ppv bbb estamos pra apenas ...             44   \n",
       "23  como tudoo....fotos a Deus...me inje√ß√£o que m√©...             41   \n",
       "24  como tudoo....fotos a Deus...me https://t.co/v...             41   \n",
       "25  6 J√° ‚ù§ @vagner_a temporada!\\nQue na estiu boa ...             10   \n",
       "26  @jarcysdion Meu @showdavida @vanessadamata @ro...              9   \n",
       "27  #TeamGil choca que cuca #BBB21 mestre https://...             19   \n",
       "28  q 30 tvd dia na essa??? vou vai assistir? esta...             17   \n",
       "29  ver bbb!!!! SINAL PELO AMOR SEM CANAL T√î DO DI...             17   \n",
       "\n",
       "    number_diferent_tokens         bins  indices_bins  \\\n",
       "0                       11   [7.2,13.4)             1   \n",
       "1                        8   [7.2,13.4)             1   \n",
       "2                       13   [7.2,13.4)             1   \n",
       "3                        5    [1.0,7.2)             0   \n",
       "4                       13   [7.2,13.4)             1   \n",
       "5                       11   [7.2,13.4)             1   \n",
       "6                        9   [7.2,13.4)             1   \n",
       "7                       14  [13.4,19.7)             2   \n",
       "8                       12   [7.2,13.4)             1   \n",
       "9                        9   [7.2,13.4)             1   \n",
       "10                       2    [1.0,7.2)             0   \n",
       "11                      29  [25.9,32.1)             4   \n",
       "12                      21  [19.7,25.9)             3   \n",
       "13                       5    [1.0,7.2)             0   \n",
       "14                       8   [7.2,13.4)             1   \n",
       "15                      16  [13.4,19.7)             2   \n",
       "16                       6    [1.0,7.2)             0   \n",
       "17                       6    [1.0,7.2)             0   \n",
       "18                      22  [19.7,25.9)             3   \n",
       "19                      11   [7.2,13.4)             1   \n",
       "20                      15  [13.4,19.7)             2   \n",
       "21                      19  [19.7,25.9)             3   \n",
       "22                      37  [38.3,44.6)             6   \n",
       "23                      34  [38.3,44.6)             6   \n",
       "24                      34  [38.3,44.6)             6   \n",
       "25                      10   [7.2,13.4)             1   \n",
       "26                       9   [7.2,13.4)             1   \n",
       "27                      19  [13.4,19.7)             2   \n",
       "28                      16  [13.4,19.7)             2   \n",
       "29                      17  [13.4,19.7)             2   \n",
       "\n",
       "                                           text_clean  \n",
       "0   @gl b pl y @r f k lim nn_ ningu m p diu   c l ...  \n",
       "1          @h ll ntlynn  mig    r v     m gl b pl y ü•∫  \n",
       "2   @ v nsftx  mg     r v   m    p√ß√£  gl b pl y? p...  \n",
       "3       M lh r p ss    s  bbb https://t.c /H Ku8sRLkX  \n",
       "4   @gl b pl y Eu g s i,     f t   c     l   st v ...  \n",
       "5   N ss ,     v   r h rr√≠v l  r h  r   Gil   vig ...  \n",
       "6          f z  nti   lg    gl b pl y   funci  r   tv  \n",
       "7   Est u  gu r n   s pr√≥xim s  pi di s   s ri  A ...  \n",
       "8   @gl b pl y   p  r i m t r  s s u  s   O.C. UM ...  \n",
       "9   @h ll ntlynn    ss  p ss   tbm  r   gl b pl y,...  \n",
       "10                           @c du_m n ir   Gl b pl y  \n",
       "11  F l  s ri   s  QR c    √≠   D  z r     m i r fu...  \n",
       "12  g n ,  s s b m   diz r    m     ssistir    s r...  \n",
       "13  O GIL &gt;&gt;&gt;&gt;&gt; üó£üó£üó£üó£ https://t.c /v...  \n",
       "14           @gl b pl y Nunc    t nt  curti      vi .  \n",
       "15  @ n v ig_ Gi   gl b pl y funci    √≠? √â     c  ...  \n",
       "16                      1 C ntr  t  s,  m   Gl b pl y  \n",
       "17     @r f k lim nn_ @gl b pl y P r b ns R f  K üëèüèªüëèüèª  \n",
       "18  @gl b pl y  g r     x mpl ,  st u  nt n  pul r...  \n",
       "19  @j ic m r  C nc l i   N tflix pr   ssi r   Gl ...  \n",
       "20  @M thc rv lh p Cl r ! M s    gu  l√°   inst   n...  \n",
       "21     g r    gl b pl y bug u    u     i   n   u p...  \n",
       "22  g n ,  m    v r bbb   gl b pl y   tv? n c nsig...  \n",
       "23  @gl b pl y @r f k lim nn_ El  pr cis     ju  U...  \n",
       "24  @gl b pl y @r f k lim nn_ El  pr cis     ju  U...  \n",
       "25  @v gn r_  @gl b pl y J√°  stiu   6  m   !\\nQu  ...  \n",
       "26  @j rcysdi n @v n ss  m t  @r b rt c rl s @sh w...  \n",
       "27  C i   st√° c zinh n    ch c   m  ch u       Fiu...  \n",
       "28  tvd v i  st r   gl b pl y    t  di  30 q  r   ...  \n",
       "29  @gl b pl y PELO AMOR D DEUS T√î SEM SINAL DO CA...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final[\"text_clean\"] = data_tweets_final[\"text\"].apply(lambda x: text_cleaner(text = x,stop_words_domain =None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@globoplay @rafakalimann_ ningu√©m pediu isso c...</td>\n",
       "      <td>globoplay rafakalimann ningu√©m pediu coloca l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@hallentlynn amiga no rave n√£o tem globoplay ü•∫</td>\n",
       "      <td>hallentlynn amiga rave tem globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@evansftx amg mas no rave tem a op√ß√£o globopla...</td>\n",
       "      <td>evansftx amg no rave a op√ß√£o globoplay pq ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melhor pessoa desse bbb https://t.co/HaKu8sRLkX</td>\n",
       "      <td>Melhor pessoa desse bbb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@globoplay Eu gostei, mas de fato achei que el...</td>\n",
       "      <td>globoplay Eu gostei de fato achei ele tendo c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Eu ia ser t√£o feliz se a @globoplay adicionass...</td>\n",
       "      <td>Eu ia ser t√£o feliz a globoplay adicionasse no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Por que ela ta querendo virar a tidinha ? http...</td>\n",
       "      <td>Por ela ta querendo virar tidinha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>pelo amor, algu√©m gravou esse comercial da Raf...</td>\n",
       "      <td>pelo amor algu√©m gravou comercial Rafa Paulo p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@globoplay Joker do Vigor #BBB21</td>\n",
       "      <td>globoplay Joker Vigor BBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Voc√™s entenderam ou PB precisa desenhar? @Arth...</td>\n",
       "      <td>Voc√™s entenderam PB precisa desenhar ArthurLir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    @globoplay @rafakalimann_ ningu√©m pediu isso c...   \n",
       "1       @hallentlynn amiga no rave n√£o tem globoplay ü•∫   \n",
       "2    @evansftx amg mas no rave tem a op√ß√£o globopla...   \n",
       "3      Melhor pessoa desse bbb https://t.co/HaKu8sRLkX   \n",
       "4    @globoplay Eu gostei, mas de fato achei que el...   \n",
       "..                                                 ...   \n",
       "995  Eu ia ser t√£o feliz se a @globoplay adicionass...   \n",
       "996  Por que ela ta querendo virar a tidinha ? http...   \n",
       "997  pelo amor, algu√©m gravou esse comercial da Raf...   \n",
       "998                   @globoplay Joker do Vigor #BBB21   \n",
       "999  Voc√™s entenderam ou PB precisa desenhar? @Arth...   \n",
       "\n",
       "                                            text_clean  \n",
       "0     globoplay rafakalimann ningu√©m pediu coloca l...  \n",
       "1                hallentlynn amiga rave tem globoplay   \n",
       "2     evansftx amg no rave a op√ß√£o globoplay pq ant...  \n",
       "3                             Melhor pessoa desse bbb   \n",
       "4     globoplay Eu gostei de fato achei ele tendo c...  \n",
       "..                                                 ...  \n",
       "995  Eu ia ser t√£o feliz a globoplay adicionasse no...  \n",
       "996                 Por ela ta querendo virar tidinha   \n",
       "997  pelo amor algu√©m gravou comercial Rafa Paulo p...  \n",
       "998                         globoplay Joker Vigor BBB   \n",
       "999  Voc√™s entenderam PB precisa desenhar ArthurLir...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final[[\"text\",\"text_clean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-69-e4cc38c47788>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-69-e4cc38c47788>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    re.sub(,data_tweets_final[\"text\"][3]\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "re.sub(,data_tweets_final[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Melhor pessoa desse bbb https://t.co/HaKu8sRLkX'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'https://t.co/HaKu8sRLkX Melhor pessoa desse bbb '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Melhor pessoa desse bbb '"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\shttps([a-zA-Z√†-√∫√Ä-√ö0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+$|^https([a-zA-Z√†-√∫√Ä-√ö0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s|\\shttps([a-zA-Z√†-√∫√Ä-√ö0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s\",\" \",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Melhor pessoa desse bbb '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\shttps([a-zA-Z√†-√∫√Ä-√ö0-9]|[^a-zA-Z√†-√∫√Ä-√ö0-9])+$|^https([a-zA-Z√†-√∫√Ä-√ö0-9]|[^a-zA-Z√†-√∫√Ä-√ö0-9])+\\s|\\shttps([a-zA-Z√†-√∫√Ä-√ö0-9]|[^a-zA-Z√†-√∫√Ä-√ö0-9])+\\s\",\" \",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https([a-zA-Z√†-√∫√Ä-√ö0-9]|[^a-zA-Z√†-√∫√Ä-√ö0-9])+\\s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_calc_histogram(x,initial_interval, final_interval,n_bins,indice=False):\n",
    "\n",
    "    interval = np.linspace(initial_interval, final_interval, num=n_bins)\n",
    "\n",
    "    for j,i in enumerate(interval):\n",
    "\n",
    "\n",
    "        if i == interval[len(interval)-1]:\n",
    "\n",
    "            if x>=i:\n",
    "\n",
    "                \n",
    "                if indice:\n",
    "\n",
    "                    return j\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    return \"{}<\".format(x)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            if x>=i and x<interval[j+1]:\n",
    "\n",
    "                inicial = round(i, 1)\n",
    "\n",
    "                final = round(interval[j+1],1)\n",
    "\n",
    "            \n",
    "                if indice:\n",
    "\n",
    "                    return j\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    return \"[{},{})\".format(inicial,final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria√ß√£o de uma coluna com os textos sem repeti√ß√£o de palavras para ser utilizado na an√°lise explorat√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['text_unique_words'] = data_tweets_final['text'].apply(lambda x: convert_text_to_no_repeat_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo N√∫mero de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo N√∫mero de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_diferent_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_diferent_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√°ximo n√∫mero de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = data_tweets_final[\"number_tokens\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.84171271271282"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final[\"number_tokens\"].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√≠nimo n√∫mero de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = data_tweets_final[\"number_tokens\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados para o histograma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['bins'] = data_tweets_final['number_tokens'].apply(lambda x: function_to_calc_histogram(x,initial_interval = min_count, final_interval = max_count,n_bins = 10,indice=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['indices_bins'] = data_tweets_final['number_tokens'].apply(lambda x: function_to_calc_histogram(x,initial_interval = min_count, final_interval = max_count,n_bins = 10,indice=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_histogram = data_tweets_final.groupby([\"bins\",\"indices_bins\"]).sum().sort_values(by=[\"indices_bins\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_histogram.reset_index(drop=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins</th>\n",
       "      <th>indices_bins</th>\n",
       "      <th>number_tokens</th>\n",
       "      <th>number_diferent_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>1581</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>3225</td>\n",
       "      <td>3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>2376</td>\n",
       "      <td>2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>2195</td>\n",
       "      <td>2058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25.9,32.1)</td>\n",
       "      <td>4</td>\n",
       "      <td>1223</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[32.1,38.3)</td>\n",
       "      <td>5</td>\n",
       "      <td>1338</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>1341</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[44.6,50.8)</td>\n",
       "      <td>7</td>\n",
       "      <td>433</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[50.8,57.0)</td>\n",
       "      <td>8</td>\n",
       "      <td>104</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57&lt;</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bins  indices_bins  number_tokens  number_diferent_tokens\n",
       "0    [1.0,7.2)             0           1581                    1576\n",
       "1   [7.2,13.4)             1           3225                    3175\n",
       "2  [13.4,19.7)             2           2376                    2290\n",
       "3  [19.7,25.9)             3           2195                    2058\n",
       "4  [25.9,32.1)             4           1223                    1129\n",
       "5  [32.1,38.3)             5           1338                    1226\n",
       "6  [38.3,44.6)             6           1341                    1197\n",
       "7  [44.6,50.8)             7            433                     370\n",
       "8  [50.8,57.0)             8            104                      91\n",
       "9          57<             9             57                      48"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1.0,7.2)',\n",
       " '[7.2,13.4)',\n",
       " '[13.4,19.7)',\n",
       " '[19.7,25.9)',\n",
       " '[25.9,32.1)',\n",
       " '[32.1,38.3)',\n",
       " '[38.3,44.6)',\n",
       " '[44.6,50.8)',\n",
       " '[50.8,57.0)',\n",
       " '57<']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_histogram[\"bins\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1581, 3225, 2376, 2195, 1223, 1338, 1341, 433, 104, 57]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_histogram[\"number_tokens\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_mean = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.924, 0.319, 0.319, 0.284, 0.252, 0.25, 0.213, 0.165, 0.148, 0.139]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"MEAN\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['globoplay',\n",
       " 'co',\n",
       " 'https',\n",
       " 'de',\n",
       " 'que',\n",
       " 'rafakalimann_',\n",
       " 'eu',\n",
       " 'no',\n",
       " 'do',\n",
       " 'da']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"WORDS\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum = plot_bar_count_words(text_column='text_unique_words',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum[\"P_DOCS\"] =  df_report_sum[\"SUM\"]/len(data_tweets_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM</th>\n",
       "      <th>WORDS</th>\n",
       "      <th>P_DOCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>906</td>\n",
       "      <td>globoplay</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>319</td>\n",
       "      <td>https</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>319</td>\n",
       "      <td>co</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>244</td>\n",
       "      <td>rafakalimann_</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>225</td>\n",
       "      <td>de</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>205</td>\n",
       "      <td>que</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>178</td>\n",
       "      <td>eu</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>145</td>\n",
       "      <td>no</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>126</td>\n",
       "      <td>da</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>116</td>\n",
       "      <td>do</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUM          WORDS  P_DOCS\n",
       "1345  906      globoplay   0.906\n",
       "1455  319          https   0.319\n",
       "669   319             co   0.319\n",
       "2491  244  rafakalimann_   0.244\n",
       "824   225             de   0.225\n",
       "2461  205            que   0.205\n",
       "1127  178             eu   0.178\n",
       "2010  145             no   0.145\n",
       "802   126             da   0.126\n",
       "940   116             do   0.116"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>924</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>319</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>319</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>284</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>252</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>250</td>\n",
       "      <td>rafakalimann_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>213</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>165</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>148</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>139</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUM          WORDS\n",
       "1345  924      globoplay\n",
       "669   319             co\n",
       "1455  319          https\n",
       "824   284             de\n",
       "2461  252            que\n",
       "2491  250  rafakalimann_\n",
       "1127  213             eu\n",
       "2010  165             no\n",
       "940   148             do\n",
       "802   139             da"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_mean = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>0.072245</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>0.056826</td>\n",
       "      <td>rafakalimann_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0.041320</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.041320</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.034915</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>0.030825</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>0.027536</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.027514</td>\n",
       "      <td>voc√™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>0.024422</td>\n",
       "      <td>merece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.023554</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MEAN          WORDS\n",
       "1345  0.072245      globoplay\n",
       "2491  0.056826  rafakalimann_\n",
       "669   0.041320             co\n",
       "1455  0.041320          https\n",
       "824   0.034915             de\n",
       "2461  0.030825            que\n",
       "1127  0.027536             eu\n",
       "3104  0.027514           voc√™\n",
       "1849  0.024422         merece\n",
       "2010  0.023554             no"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_tfidf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MAX TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_max = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MAX',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAX</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>0.125010</td>\n",
       "      <td>rafakalimann_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.094182</td>\n",
       "      <td>voc√™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>0.089983</td>\n",
       "      <td>merece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>0.080011</td>\n",
       "      <td>orgulho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>0.077694</td>\n",
       "      <td>vc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>0.074110</td>\n",
       "      <td>paulovieirareal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.073977</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0.072069</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.072069</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.068867</td>\n",
       "      <td>amor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MAX            WORDS\n",
       "2491  0.125010    rafakalimann_\n",
       "3104  0.094182             voc√™\n",
       "1849  0.089983           merece\n",
       "2091  0.080011          orgulho\n",
       "3040  0.077694               vc\n",
       "2190  0.074110  paulovieirareal\n",
       "824   0.073977               de\n",
       "669   0.072069               co\n",
       "1455  0.072069            https\n",
       "242   0.068867             amor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_tfidf_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
