{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/julio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from api_keys import BEARER_TOKEN\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções (Análise Exploratória)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para plotar bar plot com a contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_count_words(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para plotar bar plot com tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_tf_idf(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    \"MAX\":data_vect.std(axis=0)\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text):\n",
    "\n",
    "    quantity_of_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_words = [i for i in quantity_of_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_words = len(quantity_of_words)\n",
    "\n",
    "    return quantity_of_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para contagem de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_diferent_words(text):\n",
    "\n",
    "    quantity_of_diferent_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_diferent_words = [i for i in quantity_of_diferent_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_diferent_words = set(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = list(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = len(quantity_of_diferent_words)\n",
    "\n",
    "    return quantity_of_diferent_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para criar textos sem repetição de palavras para ser utilizado na análise exploratória "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_no_repeat_words(text):\n",
    "\n",
    "    text_with_no_repeat_words = text.split(\" \")\n",
    "\n",
    "    text_with_no_repeat_words = [i for i in text_with_no_repeat_words if i!=\"\"]\n",
    "\n",
    "    text_with_no_repeat_words = set(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = list(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = \" \".join(text_with_no_repeat_words)\n",
    "\n",
    "    return text_with_no_repeat_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para o pré-processamento do texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "    collection_text = [ {\"text\" : text}]\n",
    "    text = pd.DataFrame(collection_text)\n",
    "\n",
    "    text['text'] = text['text'].astype('str')\n",
    "    text['text'] = text['text'].str.lower()\n",
    "    text['text'] = text['text'].str.replace('\\n',' ')\n",
    "    text['text'] = text['text'].str.replace('\\r',' ')\n",
    "    text['text'] = text['text'].apply(lambda x: norm('NFKD', x).encode('ascii', 'ignore').decode())\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(nltk_stopwords))\n",
    "    text['text'] = text['text'].str.replace(pat,'')\n",
    "    text = text['text'].values[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para limpeza dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text,stop_words_domain =None):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "    regex_stop_words = '|'.join(nltk_stopwords)\n",
    "    text = re.sub(r\"\\shttps([a-zA-Zà-úÀ-Ú0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+$|^https([a-zA-Zà-úÀ-Ú0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s|\\shttps([a-zA-Zà-úÀ-Ú0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s\",\" \",text)\n",
    "    text = re.sub(r\"[^a-zA-ZÀ-Úà-ú]+\",\" \",text)\n",
    "    text = re.sub(r\"\\s({})\\s|\\s({})$|^({})\\s\".format(regex_stop_words,regex_stop_words,regex_stop_words),\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \" uhahua,não\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' uhahua '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de',\n",
       " 'a',\n",
       " 'o',\n",
       " 'que',\n",
       " 'e',\n",
       " 'é',\n",
       " 'do',\n",
       " 'da',\n",
       " 'em',\n",
       " 'um',\n",
       " 'para',\n",
       " 'com',\n",
       " 'não',\n",
       " 'uma',\n",
       " 'os',\n",
       " 'no',\n",
       " 'se',\n",
       " 'na',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'as',\n",
       " 'dos',\n",
       " 'como',\n",
       " 'mas',\n",
       " 'ao',\n",
       " 'ele',\n",
       " 'das',\n",
       " 'à',\n",
       " 'seu',\n",
       " 'sua',\n",
       " 'ou',\n",
       " 'quando',\n",
       " 'muito',\n",
       " 'nos',\n",
       " 'já',\n",
       " 'eu',\n",
       " 'também',\n",
       " 'só',\n",
       " 'pelo',\n",
       " 'pela',\n",
       " 'até',\n",
       " 'isso',\n",
       " 'ela',\n",
       " 'entre',\n",
       " 'depois',\n",
       " 'sem',\n",
       " 'mesmo',\n",
       " 'aos',\n",
       " 'seus',\n",
       " 'quem',\n",
       " 'nas',\n",
       " 'me',\n",
       " 'esse',\n",
       " 'eles',\n",
       " 'você',\n",
       " 'essa',\n",
       " 'num',\n",
       " 'nem',\n",
       " 'suas',\n",
       " 'meu',\n",
       " 'às',\n",
       " 'minha',\n",
       " 'numa',\n",
       " 'pelos',\n",
       " 'elas',\n",
       " 'qual',\n",
       " 'nós',\n",
       " 'lhe',\n",
       " 'deles',\n",
       " 'essas',\n",
       " 'esses',\n",
       " 'pelas',\n",
       " 'este',\n",
       " 'dele',\n",
       " 'tu',\n",
       " 'te',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'lhes',\n",
       " 'meus',\n",
       " 'minhas',\n",
       " 'teu',\n",
       " 'tua',\n",
       " 'teus',\n",
       " 'tuas',\n",
       " 'nosso',\n",
       " 'nossa',\n",
       " 'nossos',\n",
       " 'nossas',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'esta',\n",
       " 'estes',\n",
       " 'estas',\n",
       " 'aquele',\n",
       " 'aquela',\n",
       " 'aqueles',\n",
       " 'aquelas',\n",
       " 'isto',\n",
       " 'aquilo',\n",
       " 'estou',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estão',\n",
       " 'estive',\n",
       " 'esteve',\n",
       " 'estivemos',\n",
       " 'estiveram',\n",
       " 'estava',\n",
       " 'estávamos',\n",
       " 'estavam',\n",
       " 'estivera',\n",
       " 'estivéramos',\n",
       " 'esteja',\n",
       " 'estejamos',\n",
       " 'estejam',\n",
       " 'estivesse',\n",
       " 'estivéssemos',\n",
       " 'estivessem',\n",
       " 'estiver',\n",
       " 'estivermos',\n",
       " 'estiverem',\n",
       " 'hei',\n",
       " 'há',\n",
       " 'havemos',\n",
       " 'hão',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houveram',\n",
       " 'houvera',\n",
       " 'houvéramos',\n",
       " 'haja',\n",
       " 'hajamos',\n",
       " 'hajam',\n",
       " 'houvesse',\n",
       " 'houvéssemos',\n",
       " 'houvessem',\n",
       " 'houver',\n",
       " 'houvermos',\n",
       " 'houverem',\n",
       " 'houverei',\n",
       " 'houverá',\n",
       " 'houveremos',\n",
       " 'houverão',\n",
       " 'houveria',\n",
       " 'houveríamos',\n",
       " 'houveriam',\n",
       " 'sou',\n",
       " 'somos',\n",
       " 'são',\n",
       " 'era',\n",
       " 'éramos',\n",
       " 'eram',\n",
       " 'fui',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'foram',\n",
       " 'fora',\n",
       " 'fôramos',\n",
       " 'seja',\n",
       " 'sejamos',\n",
       " 'sejam',\n",
       " 'fosse',\n",
       " 'fôssemos',\n",
       " 'fossem',\n",
       " 'for',\n",
       " 'formos',\n",
       " 'forem',\n",
       " 'serei',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'serão',\n",
       " 'seria',\n",
       " 'seríamos',\n",
       " 'seriam',\n",
       " 'tenho',\n",
       " 'tem',\n",
       " 'temos',\n",
       " 'tém',\n",
       " 'tinha',\n",
       " 'tínhamos',\n",
       " 'tinham',\n",
       " 'tive',\n",
       " 'teve',\n",
       " 'tivemos',\n",
       " 'tiveram',\n",
       " 'tivera',\n",
       " 'tivéramos',\n",
       " 'tenha',\n",
       " 'tenhamos',\n",
       " 'tenham',\n",
       " 'tivesse',\n",
       " 'tivéssemos',\n",
       " 'tivessem',\n",
       " 'tiver',\n",
       " 'tivermos',\n",
       " 'tiverem',\n",
       " 'terei',\n",
       " 'terá',\n",
       " 'teremos',\n",
       " 'terão',\n",
       " 'teria',\n",
       " 'teríamos',\n",
       " 'teriam']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções (Extração de Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def create_url(query = \"@globoplay -is:retweet\",until_id=None):\n",
    "    \n",
    "    #query = \"@BBB -is:retweet\"\n",
    "    #\"from:twitterdev -is:retweet\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    \n",
    "    if until_id:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100&until_id={}\".format(\n",
    "            query,until_id\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100\".format(\n",
    "            query\n",
    "        )\n",
    "            \n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def extract_100_tweets(query = \"@BBB -is:retweet\",until_id=None):\n",
    "    bearer_token = BEARER_TOKEN\n",
    "    url = create_url(query,until_id)\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    data_tweets = json.dumps(json_response, indent=4, sort_keys=True)\n",
    "    return json_response\n",
    "\n",
    "def extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",start_from_id=None,query=\"@BBB\"):\n",
    "    \n",
    "    \n",
    "    oldest_id = None\n",
    "    \n",
    "    for i in tqdm(range(qnt_cycle)):\n",
    "    \n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            #extract the 100 tweets first\n",
    "            \n",
    "            if start_from_id:\n",
    "        \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=None)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=start_from_id)\n",
    "                \n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets[\"data\"])\n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            \n",
    "            oldest_id = data_tweets['meta']['oldest_id']\n",
    "            \n",
    "            oldest_date = date_extraction\n",
    "            \n",
    "            df_data_tweets = df_data_tweets_temp.copy()\n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,date_extraction_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file,sep=\",\")\n",
    "            \n",
    "    \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            #extract more 100 tweets older\n",
    "            \n",
    "            data_tweets_temp = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=oldest_id)\n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets_temp[\"data\"])\n",
    "            \n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            oldest_id = data_tweets_temp['meta']['oldest_id']\n",
    "            \n",
    "            df_data_tweets = pd.concat([df_data_tweets,df_data_tweets_temp.copy()])\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets.reset_index(inplace=True,drop=True)\n",
    "            \n",
    "            \n",
    "            # remove old files\n",
    "            \n",
    "            os.remove(name_file)\n",
    "            \n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            oldest_date_str = str(oldest_date).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,oldest_date_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file.format(folder),sep=\",\")\n",
    "            \n",
    "            \n",
    "\n",
    "    return df_data_tweets\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "data_tweets_final = extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",query=\"globoplay\")#,start_from_id=\"1367600965277384706\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date_extraction</th>\n",
       "      <th>text_unique_words</th>\n",
       "      <th>number_tokens</th>\n",
       "      <th>number_diferent_tokens</th>\n",
       "      <th>bins</th>\n",
       "      <th>indices_bins</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1383949586826334212</td>\n",
       "      <td>@globoplay @rafakalimann_ ninguém pediu isso c...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>usurpadora logo a no pediu coloca catálogo @gl...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y @r f k lim nn_ ningu m p diu   c l ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1383949548708499457</td>\n",
       "      <td>@hallentlynn amiga no rave não tem globoplay 🥺</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@hallentlynn no rave tem não amiga globoplay 🥺</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@h ll ntlynn  mig    r v     m gl b pl y 🥺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1383949443326611459</td>\n",
       "      <td>@evansftx amg mas no rave tem a opção globopla...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>a pq mas no antes opção tinha amg rave tem não...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@ v nsftx  mg     r v   m    pçã  gl b pl y? p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1383949414197186561</td>\n",
       "      <td>Melhor pessoa desse bbb https://t.co/HaKu8sRLkX</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>desse bbb Melhor pessoa https://t.co/HaKu8sRLkX</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>M lh r p ss    s  bbb https://t.c /H Ku8sRLkX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1383949406836191237</td>\n",
       "      <td>@globoplay Eu gostei, mas de fato achei que el...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>gostei, tendo mas 😅😅😅😅 ele estava fato convuls...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y Eu g s i,     f t   c     l   st v ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1383949316419555335</td>\n",
       "      <td>Nossa, como deve ser horrível ser hater do Gil...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como ser 🤭✌🏻 Gil horrível hater vigor Nossa, h...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>N ss ,     v   r h rrív l  r h  r   Gil   vig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383949242562084877</td>\n",
       "      <td>não faz sentido algum minha globoplay não func...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>algum faz sentido na minha não funcionar tv gl...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>f z  nti   lg    gl b pl y   funci  r   tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1383949219149451273</td>\n",
       "      <td>Estou aguardando pelos próximos episódios da s...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>da A episódios aguardando vacinas pelos das sé...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>Est u  gu r n   s próxim s  pi di s   s ri  A ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1383949162064998402</td>\n",
       "      <td>@globoplay quando poderei matar as saudades de...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>quando matar UM NO @globoplay as de O.C. poder...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y   p  r i m t r  s s u  s   O.C. UM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1383949094515666946</td>\n",
       "      <td>@hallentlynn se essa pessoa tbm tiver a globop...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>tiver a @hallentlynn tbm globoplay, sim se pes...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@h ll ntlynn    ss  p ss   tbm  r   gl b pl y,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1383949002995994632</td>\n",
       "      <td>@cadu_monteiroo Globoplay</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@cadu_monteiroo Globoplay</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>@c du_m n ir   Gl b pl y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1383948991755259913</td>\n",
       "      <td>Fala sério esse QR code aí do Deezer é a maior...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>a aparece maior Deezer Globo do sacanagem!. QR...</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>[25.9,32.1)</td>\n",
       "      <td>4</td>\n",
       "      <td>F l  s ri   s  QR c    í   D  z r     m i r fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1383948908703805445</td>\n",
       "      <td>gente, vocês sabem me dizer se tem como assist...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como tipo com mesmo série me assistir rave? di...</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>g n ,  s s b m   diz r    m     ssistir    s r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1383948838000492546</td>\n",
       "      <td>O GIL &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 🗣🗣🗣🗣 https://t.co/v...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; https://t.co/vitHOewEwT 🗣...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>O GIL &amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; 🗣🗣🗣🗣 https://t.c /v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1383948765199953927</td>\n",
       "      <td>@globoplay Nunca tive tanta curtida na minha v...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>tive na minha vida. Nunca @globoplay curtida t...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@gl b pl y Nunc    t nt  curti      vi .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1383948707838664707</td>\n",
       "      <td>@annavoig_ Gi o globoplay funciona aí? É só se...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>É o Gi funciona aí? dá só cadastrar que vivaço...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>@ n v ig_ Gi   gl b pl y funci    í? É     c  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1383948670064726016</td>\n",
       "      <td>1 Contra todos, tem no Globoplay</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>no Contra tem todos, 1 Globoplay</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>1 C ntr  t  s,  m   Gl b pl y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1383948621293391872</td>\n",
       "      <td>@rafakalimann_ @globoplay Parabens Rafa K 👏🏻👏🏻</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>Rafa K @globoplay Parabens @rafakalimann_ 👏🏻👏🏻</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>@r f k lim nn_ @gl b pl y P r b ns R f  K 👏🏻👏🏻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1383948574707253259</td>\n",
       "      <td>@globoplay agora por exemplo, estou tentando p...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>exemplo, por a estou canais. anuncio, agora qu...</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>@gl b pl y  g r     x mpl ,  st u  nt n  pul r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1383948502904958980</td>\n",
       "      <td>@joicemara Cancelei a Netflix pra assinar a Gl...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>a Cancelei e @joicemara melhor foi assinar Net...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@j ic m r  C nc l i   N tflix pr   ssi r   Gl ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1383948348810428420</td>\n",
       "      <td>@Mathcarvalhop Claro! Mas me segue lá no insta...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@Mathcarvalhop https://t.co/5cjNxV9Sb2 no http...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>@M thc rv lh p Cl r ! M s    gu  lá   inst   n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1383948298428444675</td>\n",
       "      <td>e agora a globoplay bugou e eu nao sei aonde e...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>série, a vou bugou eu agora nao chorar errado ...</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>g r    gl b pl y bug u    u     i   n   u p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1383948265977090058</td>\n",
       "      <td>gente, tem como ver bbb na globoplay pela tv? ...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como por a ver nem ppv bbb estamos pra apenas ...</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>g n ,  m    v r bbb   gl b pl y   tv? n c nsig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1383948224981995526</td>\n",
       "      <td>@globoplay @rafakalimann_ Ela precisa de ajuda...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como tudoo....fotos a Deus...me injeção que mé...</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>@gl b pl y @r f k lim nn_ El  pr cis     ju  U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1383948192635494403</td>\n",
       "      <td>@globoplay @rafakalimann_ Ela precisa de ajuda...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>como tudoo....fotos a Deus...me https://t.co/v...</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>@gl b pl y @r f k lim nn_ El  pr cis     ju  U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1383948098607583232</td>\n",
       "      <td>@vagner_a @globoplay Já estiu na 6 temporada!\\...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>6 Já ❤ @vagner_a temporada!\\nQue na estiu boa ...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@v gn r_  @gl b pl y Já  stiu   6  m   !\\nQu  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1383948096611127296</td>\n",
       "      <td>@jarcysdion @vanessadamata @robertocarlos @sho...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>@jarcysdion Meu @showdavida @vanessadamata @ro...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>@j rcysdi n @v n ss  m t  @r b rt c rl s @sh w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1383948083189338117</td>\n",
       "      <td>Caio está cozinhando e choca quem achou que só...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>#TeamGil choca que cuca #BBB21 mestre https://...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>C i   stá c zinh n    ch c   m  ch u       Fiu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1383947959872593940</td>\n",
       "      <td>tvd vai estar na globoplay só até dia 30 q por...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>q 30 tvd dia na essa??? vou vai assistir? esta...</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>tvd v i  st r   gl b pl y    t  di  30 q  r   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1383947864653524996</td>\n",
       "      <td>@globoplay PELO AMOR D DEUS TÔ SEM SINAL DO CA...</td>\n",
       "      <td>2021-04-18 22:04:46.634032</td>\n",
       "      <td>ver bbb!!!! SINAL PELO AMOR SEM CANAL TÔ DO DI...</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>@gl b pl y PELO AMOR D DEUS TÔ SEM SINAL DO CA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1383949586826334212  @globoplay @rafakalimann_ ninguém pediu isso c...   \n",
       "1   1383949548708499457     @hallentlynn amiga no rave não tem globoplay 🥺   \n",
       "2   1383949443326611459  @evansftx amg mas no rave tem a opção globopla...   \n",
       "3   1383949414197186561    Melhor pessoa desse bbb https://t.co/HaKu8sRLkX   \n",
       "4   1383949406836191237  @globoplay Eu gostei, mas de fato achei que el...   \n",
       "5   1383949316419555335  Nossa, como deve ser horrível ser hater do Gil...   \n",
       "6   1383949242562084877  não faz sentido algum minha globoplay não func...   \n",
       "7   1383949219149451273  Estou aguardando pelos próximos episódios da s...   \n",
       "8   1383949162064998402  @globoplay quando poderei matar as saudades de...   \n",
       "9   1383949094515666946  @hallentlynn se essa pessoa tbm tiver a globop...   \n",
       "10  1383949002995994632                          @cadu_monteiroo Globoplay   \n",
       "11  1383948991755259913  Fala sério esse QR code aí do Deezer é a maior...   \n",
       "12  1383948908703805445  gente, vocês sabem me dizer se tem como assist...   \n",
       "13  1383948838000492546  O GIL &gt;&gt;&gt;&gt;&gt; 🗣🗣🗣🗣 https://t.co/v...   \n",
       "14  1383948765199953927  @globoplay Nunca tive tanta curtida na minha v...   \n",
       "15  1383948707838664707  @annavoig_ Gi o globoplay funciona aí? É só se...   \n",
       "16  1383948670064726016                   1 Contra todos, tem no Globoplay   \n",
       "17  1383948621293391872     @rafakalimann_ @globoplay Parabens Rafa K 👏🏻👏🏻   \n",
       "18  1383948574707253259  @globoplay agora por exemplo, estou tentando p...   \n",
       "19  1383948502904958980  @joicemara Cancelei a Netflix pra assinar a Gl...   \n",
       "20  1383948348810428420  @Mathcarvalhop Claro! Mas me segue lá no insta...   \n",
       "21  1383948298428444675  e agora a globoplay bugou e eu nao sei aonde e...   \n",
       "22  1383948265977090058  gente, tem como ver bbb na globoplay pela tv? ...   \n",
       "23  1383948224981995526  @globoplay @rafakalimann_ Ela precisa de ajuda...   \n",
       "24  1383948192635494403  @globoplay @rafakalimann_ Ela precisa de ajuda...   \n",
       "25  1383948098607583232  @vagner_a @globoplay Já estiu na 6 temporada!\\...   \n",
       "26  1383948096611127296  @jarcysdion @vanessadamata @robertocarlos @sho...   \n",
       "27  1383948083189338117  Caio está cozinhando e choca quem achou que só...   \n",
       "28  1383947959872593940  tvd vai estar na globoplay só até dia 30 q por...   \n",
       "29  1383947864653524996  @globoplay PELO AMOR D DEUS TÔ SEM SINAL DO CA...   \n",
       "\n",
       "              date_extraction  \\\n",
       "0  2021-04-18 22:04:46.634032   \n",
       "1  2021-04-18 22:04:46.634032   \n",
       "2  2021-04-18 22:04:46.634032   \n",
       "3  2021-04-18 22:04:46.634032   \n",
       "4  2021-04-18 22:04:46.634032   \n",
       "5  2021-04-18 22:04:46.634032   \n",
       "6  2021-04-18 22:04:46.634032   \n",
       "7  2021-04-18 22:04:46.634032   \n",
       "8  2021-04-18 22:04:46.634032   \n",
       "9  2021-04-18 22:04:46.634032   \n",
       "10 2021-04-18 22:04:46.634032   \n",
       "11 2021-04-18 22:04:46.634032   \n",
       "12 2021-04-18 22:04:46.634032   \n",
       "13 2021-04-18 22:04:46.634032   \n",
       "14 2021-04-18 22:04:46.634032   \n",
       "15 2021-04-18 22:04:46.634032   \n",
       "16 2021-04-18 22:04:46.634032   \n",
       "17 2021-04-18 22:04:46.634032   \n",
       "18 2021-04-18 22:04:46.634032   \n",
       "19 2021-04-18 22:04:46.634032   \n",
       "20 2021-04-18 22:04:46.634032   \n",
       "21 2021-04-18 22:04:46.634032   \n",
       "22 2021-04-18 22:04:46.634032   \n",
       "23 2021-04-18 22:04:46.634032   \n",
       "24 2021-04-18 22:04:46.634032   \n",
       "25 2021-04-18 22:04:46.634032   \n",
       "26 2021-04-18 22:04:46.634032   \n",
       "27 2021-04-18 22:04:46.634032   \n",
       "28 2021-04-18 22:04:46.634032   \n",
       "29 2021-04-18 22:04:46.634032   \n",
       "\n",
       "                                    text_unique_words  number_tokens  \\\n",
       "0   usurpadora logo a no pediu coloca catálogo @gl...             11   \n",
       "1      @hallentlynn no rave tem não amiga globoplay 🥺              8   \n",
       "2   a pq mas no antes opção tinha amg rave tem não...             13   \n",
       "3     desse bbb Melhor pessoa https://t.co/HaKu8sRLkX              5   \n",
       "4   gostei, tendo mas 😅😅😅😅 ele estava fato convuls...             13   \n",
       "5   como ser 🤭✌🏻 Gil horrível hater vigor Nossa, h...             13   \n",
       "6   algum faz sentido na minha não funcionar tv gl...             10   \n",
       "7   da A episódios aguardando vacinas pelos das sé...             14   \n",
       "8   quando matar UM NO @globoplay as de O.C. poder...             12   \n",
       "9   tiver a @hallentlynn tbm globoplay, sim se pes...              9   \n",
       "10                          @cadu_monteiroo Globoplay              2   \n",
       "11  a aparece maior Deezer Globo do sacanagem!. QR...             31   \n",
       "12  como tipo com mesmo série me assistir rave? di...             21   \n",
       "13  &gt;&gt;&gt;&gt;&gt; https://t.co/vitHOewEwT 🗣...              5   \n",
       "14  tive na minha vida. Nunca @globoplay curtida t...              8   \n",
       "15  É o Gi funciona aí? dá só cadastrar que vivaço...             16   \n",
       "16                   no Contra tem todos, 1 Globoplay              6   \n",
       "17     Rafa K @globoplay Parabens @rafakalimann_ 👏🏻👏🏻              6   \n",
       "18  exemplo, por a estou canais. anuncio, agora qu...             23   \n",
       "19  a Cancelei e @joicemara melhor foi assinar Net...             13   \n",
       "20  @Mathcarvalhop https://t.co/5cjNxV9Sb2 no http...             15   \n",
       "21  série, a vou bugou eu agora nao chorar errado ...             21   \n",
       "22  como por a ver nem ppv bbb estamos pra apenas ...             44   \n",
       "23  como tudoo....fotos a Deus...me injeção que mé...             41   \n",
       "24  como tudoo....fotos a Deus...me https://t.co/v...             41   \n",
       "25  6 Já ❤ @vagner_a temporada!\\nQue na estiu boa ...             10   \n",
       "26  @jarcysdion Meu @showdavida @vanessadamata @ro...              9   \n",
       "27  #TeamGil choca que cuca #BBB21 mestre https://...             19   \n",
       "28  q 30 tvd dia na essa??? vou vai assistir? esta...             17   \n",
       "29  ver bbb!!!! SINAL PELO AMOR SEM CANAL TÔ DO DI...             17   \n",
       "\n",
       "    number_diferent_tokens         bins  indices_bins  \\\n",
       "0                       11   [7.2,13.4)             1   \n",
       "1                        8   [7.2,13.4)             1   \n",
       "2                       13   [7.2,13.4)             1   \n",
       "3                        5    [1.0,7.2)             0   \n",
       "4                       13   [7.2,13.4)             1   \n",
       "5                       11   [7.2,13.4)             1   \n",
       "6                        9   [7.2,13.4)             1   \n",
       "7                       14  [13.4,19.7)             2   \n",
       "8                       12   [7.2,13.4)             1   \n",
       "9                        9   [7.2,13.4)             1   \n",
       "10                       2    [1.0,7.2)             0   \n",
       "11                      29  [25.9,32.1)             4   \n",
       "12                      21  [19.7,25.9)             3   \n",
       "13                       5    [1.0,7.2)             0   \n",
       "14                       8   [7.2,13.4)             1   \n",
       "15                      16  [13.4,19.7)             2   \n",
       "16                       6    [1.0,7.2)             0   \n",
       "17                       6    [1.0,7.2)             0   \n",
       "18                      22  [19.7,25.9)             3   \n",
       "19                      11   [7.2,13.4)             1   \n",
       "20                      15  [13.4,19.7)             2   \n",
       "21                      19  [19.7,25.9)             3   \n",
       "22                      37  [38.3,44.6)             6   \n",
       "23                      34  [38.3,44.6)             6   \n",
       "24                      34  [38.3,44.6)             6   \n",
       "25                      10   [7.2,13.4)             1   \n",
       "26                       9   [7.2,13.4)             1   \n",
       "27                      19  [13.4,19.7)             2   \n",
       "28                      16  [13.4,19.7)             2   \n",
       "29                      17  [13.4,19.7)             2   \n",
       "\n",
       "                                           text_clean  \n",
       "0   @gl b pl y @r f k lim nn_ ningu m p diu   c l ...  \n",
       "1          @h ll ntlynn  mig    r v     m gl b pl y 🥺  \n",
       "2   @ v nsftx  mg     r v   m    pçã  gl b pl y? p...  \n",
       "3       M lh r p ss    s  bbb https://t.c /H Ku8sRLkX  \n",
       "4   @gl b pl y Eu g s i,     f t   c     l   st v ...  \n",
       "5   N ss ,     v   r h rrív l  r h  r   Gil   vig ...  \n",
       "6          f z  nti   lg    gl b pl y   funci  r   tv  \n",
       "7   Est u  gu r n   s próxim s  pi di s   s ri  A ...  \n",
       "8   @gl b pl y   p  r i m t r  s s u  s   O.C. UM ...  \n",
       "9   @h ll ntlynn    ss  p ss   tbm  r   gl b pl y,...  \n",
       "10                           @c du_m n ir   Gl b pl y  \n",
       "11  F l  s ri   s  QR c    í   D  z r     m i r fu...  \n",
       "12  g n ,  s s b m   diz r    m     ssistir    s r...  \n",
       "13  O GIL &gt;&gt;&gt;&gt;&gt; 🗣🗣🗣🗣 https://t.c /v...  \n",
       "14           @gl b pl y Nunc    t nt  curti      vi .  \n",
       "15  @ n v ig_ Gi   gl b pl y funci    í? É     c  ...  \n",
       "16                      1 C ntr  t  s,  m   Gl b pl y  \n",
       "17     @r f k lim nn_ @gl b pl y P r b ns R f  K 👏🏻👏🏻  \n",
       "18  @gl b pl y  g r     x mpl ,  st u  nt n  pul r...  \n",
       "19  @j ic m r  C nc l i   N tflix pr   ssi r   Gl ...  \n",
       "20  @M thc rv lh p Cl r ! M s    gu  lá   inst   n...  \n",
       "21     g r    gl b pl y bug u    u     i   n   u p...  \n",
       "22  g n ,  m    v r bbb   gl b pl y   tv? n c nsig...  \n",
       "23  @gl b pl y @r f k lim nn_ El  pr cis     ju  U...  \n",
       "24  @gl b pl y @r f k lim nn_ El  pr cis     ju  U...  \n",
       "25  @v gn r_  @gl b pl y Já  stiu   6  m   !\\nQu  ...  \n",
       "26  @j rcysdi n @v n ss  m t  @r b rt c rl s @sh w...  \n",
       "27  C i   stá c zinh n    ch c   m  ch u       Fiu...  \n",
       "28  tvd v i  st r   gl b pl y    t  di  30 q  r   ...  \n",
       "29  @gl b pl y PELO AMOR D DEUS TÔ SEM SINAL DO CA...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final[\"text_clean\"] = data_tweets_final[\"text\"].apply(lambda x: text_cleaner(text = x,stop_words_domain =None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@globoplay @rafakalimann_ ninguém pediu isso c...</td>\n",
       "      <td>globoplay rafakalimann ninguém pediu coloca l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@hallentlynn amiga no rave não tem globoplay 🥺</td>\n",
       "      <td>hallentlynn amiga rave tem globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@evansftx amg mas no rave tem a opção globopla...</td>\n",
       "      <td>evansftx amg no rave a opção globoplay pq ant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Melhor pessoa desse bbb https://t.co/HaKu8sRLkX</td>\n",
       "      <td>Melhor pessoa desse bbb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@globoplay Eu gostei, mas de fato achei que el...</td>\n",
       "      <td>globoplay Eu gostei de fato achei ele tendo c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Eu ia ser tão feliz se a @globoplay adicionass...</td>\n",
       "      <td>Eu ia ser tão feliz a globoplay adicionasse no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Por que ela ta querendo virar a tidinha ? http...</td>\n",
       "      <td>Por ela ta querendo virar tidinha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>pelo amor, alguém gravou esse comercial da Raf...</td>\n",
       "      <td>pelo amor alguém gravou comercial Rafa Paulo p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>@globoplay Joker do Vigor #BBB21</td>\n",
       "      <td>globoplay Joker Vigor BBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Vocês entenderam ou PB precisa desenhar? @Arth...</td>\n",
       "      <td>Vocês entenderam PB precisa desenhar ArthurLir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    @globoplay @rafakalimann_ ninguém pediu isso c...   \n",
       "1       @hallentlynn amiga no rave não tem globoplay 🥺   \n",
       "2    @evansftx amg mas no rave tem a opção globopla...   \n",
       "3      Melhor pessoa desse bbb https://t.co/HaKu8sRLkX   \n",
       "4    @globoplay Eu gostei, mas de fato achei que el...   \n",
       "..                                                 ...   \n",
       "995  Eu ia ser tão feliz se a @globoplay adicionass...   \n",
       "996  Por que ela ta querendo virar a tidinha ? http...   \n",
       "997  pelo amor, alguém gravou esse comercial da Raf...   \n",
       "998                   @globoplay Joker do Vigor #BBB21   \n",
       "999  Vocês entenderam ou PB precisa desenhar? @Arth...   \n",
       "\n",
       "                                            text_clean  \n",
       "0     globoplay rafakalimann ninguém pediu coloca l...  \n",
       "1                hallentlynn amiga rave tem globoplay   \n",
       "2     evansftx amg no rave a opção globoplay pq ant...  \n",
       "3                             Melhor pessoa desse bbb   \n",
       "4     globoplay Eu gostei de fato achei ele tendo c...  \n",
       "..                                                 ...  \n",
       "995  Eu ia ser tão feliz a globoplay adicionasse no...  \n",
       "996                 Por ela ta querendo virar tidinha   \n",
       "997  pelo amor alguém gravou comercial Rafa Paulo p...  \n",
       "998                         globoplay Joker Vigor BBB   \n",
       "999  Vocês entenderam PB precisa desenhar ArthurLir...  \n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final[[\"text\",\"text_clean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-69-e4cc38c47788>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-69-e4cc38c47788>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    re.sub(,data_tweets_final[\"text\"][3]\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "re.sub(,data_tweets_final[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Melhor pessoa desse bbb https://t.co/HaKu8sRLkX'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'https://t.co/HaKu8sRLkX Melhor pessoa desse bbb '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Melhor pessoa desse bbb '"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\shttps([a-zA-Zà-úÀ-Ú0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+$|^https([a-zA-Zà-úÀ-Ú0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s|\\shttps([a-zA-Zà-úÀ-Ú0-9]|[-()\\\"#/@;:<>{}`+=~|.!?,])+\\s\",\" \",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Melhor pessoa desse bbb '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\shttps([a-zA-Zà-úÀ-Ú0-9]|[^a-zA-Zà-úÀ-Ú0-9])+$|^https([a-zA-Zà-úÀ-Ú0-9]|[^a-zA-Zà-úÀ-Ú0-9])+\\s|\\shttps([a-zA-Zà-úÀ-Ú0-9]|[^a-zA-Zà-úÀ-Ú0-9])+\\s\",\" \",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https([a-zA-Zà-úÀ-Ú0-9]|[^a-zA-Zà-úÀ-Ú0-9])+\\s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_to_calc_histogram(x,initial_interval, final_interval,n_bins,indice=False):\n",
    "\n",
    "    interval = np.linspace(initial_interval, final_interval, num=n_bins)\n",
    "\n",
    "    for j,i in enumerate(interval):\n",
    "\n",
    "\n",
    "        if i == interval[len(interval)-1]:\n",
    "\n",
    "            if x>=i:\n",
    "\n",
    "                \n",
    "                if indice:\n",
    "\n",
    "                    return j\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    return \"{}<\".format(x)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            if x>=i and x<interval[j+1]:\n",
    "\n",
    "                inicial = round(i, 1)\n",
    "\n",
    "                final = round(interval[j+1],1)\n",
    "\n",
    "            \n",
    "                if indice:\n",
    "\n",
    "                    return j\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    return \"[{},{})\".format(inicial,final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de uma coluna com os textos sem repetição de palavras para ser utilizado na análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['text_unique_words'] = data_tweets_final['text'].apply(lambda x: convert_text_to_no_repeat_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo Número de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo Número de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_diferent_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_diferent_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máximo número de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_count = data_tweets_final[\"number_tokens\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.84171271271282"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final[\"number_tokens\"].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mínimo número de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = data_tweets_final[\"number_tokens\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados para o histograma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['bins'] = data_tweets_final['number_tokens'].apply(lambda x: function_to_calc_histogram(x,initial_interval = min_count, final_interval = max_count,n_bins = 10,indice=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['indices_bins'] = data_tweets_final['number_tokens'].apply(lambda x: function_to_calc_histogram(x,initial_interval = min_count, final_interval = max_count,n_bins = 10,indice=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_histogram = data_tweets_final.groupby([\"bins\",\"indices_bins\"]).sum().sort_values(by=[\"indices_bins\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_histogram.reset_index(drop=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins</th>\n",
       "      <th>indices_bins</th>\n",
       "      <th>number_tokens</th>\n",
       "      <th>number_diferent_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0,7.2)</td>\n",
       "      <td>0</td>\n",
       "      <td>1581</td>\n",
       "      <td>1576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[7.2,13.4)</td>\n",
       "      <td>1</td>\n",
       "      <td>3225</td>\n",
       "      <td>3175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[13.4,19.7)</td>\n",
       "      <td>2</td>\n",
       "      <td>2376</td>\n",
       "      <td>2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[19.7,25.9)</td>\n",
       "      <td>3</td>\n",
       "      <td>2195</td>\n",
       "      <td>2058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[25.9,32.1)</td>\n",
       "      <td>4</td>\n",
       "      <td>1223</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[32.1,38.3)</td>\n",
       "      <td>5</td>\n",
       "      <td>1338</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[38.3,44.6)</td>\n",
       "      <td>6</td>\n",
       "      <td>1341</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[44.6,50.8)</td>\n",
       "      <td>7</td>\n",
       "      <td>433</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[50.8,57.0)</td>\n",
       "      <td>8</td>\n",
       "      <td>104</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57&lt;</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bins  indices_bins  number_tokens  number_diferent_tokens\n",
       "0    [1.0,7.2)             0           1581                    1576\n",
       "1   [7.2,13.4)             1           3225                    3175\n",
       "2  [13.4,19.7)             2           2376                    2290\n",
       "3  [19.7,25.9)             3           2195                    2058\n",
       "4  [25.9,32.1)             4           1223                    1129\n",
       "5  [32.1,38.3)             5           1338                    1226\n",
       "6  [38.3,44.6)             6           1341                    1197\n",
       "7  [44.6,50.8)             7            433                     370\n",
       "8  [50.8,57.0)             8            104                      91\n",
       "9          57<             9             57                      48"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[1.0,7.2)',\n",
       " '[7.2,13.4)',\n",
       " '[13.4,19.7)',\n",
       " '[19.7,25.9)',\n",
       " '[25.9,32.1)',\n",
       " '[32.1,38.3)',\n",
       " '[38.3,44.6)',\n",
       " '[44.6,50.8)',\n",
       " '[50.8,57.0)',\n",
       " '57<']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_histogram[\"bins\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1581, 3225, 2376, 2195, 1223, 1338, 1341, 433, 104, 57]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_histogram[\"number_tokens\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_mean = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.924, 0.319, 0.319, 0.284, 0.252, 0.25, 0.213, 0.165, 0.148, 0.139]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"MEAN\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['globoplay',\n",
       " 'co',\n",
       " 'https',\n",
       " 'de',\n",
       " 'que',\n",
       " 'rafakalimann_',\n",
       " 'eu',\n",
       " 'no',\n",
       " 'do',\n",
       " 'da']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"WORDS\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum = plot_bar_count_words(text_column='text_unique_words',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum[\"P_DOCS\"] =  df_report_sum[\"SUM\"]/len(data_tweets_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM</th>\n",
       "      <th>WORDS</th>\n",
       "      <th>P_DOCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>906</td>\n",
       "      <td>globoplay</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>319</td>\n",
       "      <td>https</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>319</td>\n",
       "      <td>co</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>244</td>\n",
       "      <td>rafakalimann_</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>225</td>\n",
       "      <td>de</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>205</td>\n",
       "      <td>que</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>178</td>\n",
       "      <td>eu</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>145</td>\n",
       "      <td>no</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>126</td>\n",
       "      <td>da</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>116</td>\n",
       "      <td>do</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUM          WORDS  P_DOCS\n",
       "1345  906      globoplay   0.906\n",
       "1455  319          https   0.319\n",
       "669   319             co   0.319\n",
       "2491  244  rafakalimann_   0.244\n",
       "824   225             de   0.225\n",
       "2461  205            que   0.205\n",
       "1127  178             eu   0.178\n",
       "2010  145             no   0.145\n",
       "802   126             da   0.126\n",
       "940   116             do   0.116"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>924</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>319</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>319</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>284</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>252</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>250</td>\n",
       "      <td>rafakalimann_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>213</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>165</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>148</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>139</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUM          WORDS\n",
       "1345  924      globoplay\n",
       "669   319             co\n",
       "1455  319          https\n",
       "824   284             de\n",
       "2461  252            que\n",
       "2491  250  rafakalimann_\n",
       "1127  213             eu\n",
       "2010  165             no\n",
       "940   148             do\n",
       "802   139             da"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_mean = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>0.072245</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>0.056826</td>\n",
       "      <td>rafakalimann_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0.041320</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.041320</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.034915</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>0.030825</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>0.027536</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.027514</td>\n",
       "      <td>você</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>0.024422</td>\n",
       "      <td>merece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.023554</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MEAN          WORDS\n",
       "1345  0.072245      globoplay\n",
       "2491  0.056826  rafakalimann_\n",
       "669   0.041320             co\n",
       "1455  0.041320          https\n",
       "824   0.034915             de\n",
       "2461  0.030825            que\n",
       "1127  0.027536             eu\n",
       "3104  0.027514           você\n",
       "1849  0.024422         merece\n",
       "2010  0.023554             no"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_tfidf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MAX TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_max = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MAX',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAX</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2491</th>\n",
       "      <td>0.125010</td>\n",
       "      <td>rafakalimann_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>0.094182</td>\n",
       "      <td>você</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>0.089983</td>\n",
       "      <td>merece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2091</th>\n",
       "      <td>0.080011</td>\n",
       "      <td>orgulho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>0.077694</td>\n",
       "      <td>vc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>0.074110</td>\n",
       "      <td>paulovieirareal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.073977</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>0.072069</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.072069</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.068867</td>\n",
       "      <td>amor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MAX            WORDS\n",
       "2491  0.125010    rafakalimann_\n",
       "3104  0.094182             você\n",
       "1849  0.089983           merece\n",
       "2091  0.080011          orgulho\n",
       "3040  0.077694               vc\n",
       "2190  0.074110  paulovieirareal\n",
       "824   0.073977               de\n",
       "669   0.072069               co\n",
       "1455  0.072069            https\n",
       "242   0.068867             amor"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_tfidf_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
