{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from api_keys import BEARER_TOKEN\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções (Análise Exploratória)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para plotar bar plot com a contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_count_words(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para plotar bar plot com tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_tf_idf(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    \"MAX\":data_vect.std(axis=0)\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text):\n",
    "\n",
    "    quantity_of_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_words = [i for i in quantity_of_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_words = len(quantity_of_words)\n",
    "\n",
    "    return quantity_of_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para contagem de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_diferent_words(text):\n",
    "\n",
    "    quantity_of_diferent_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_diferent_words = [i for i in quantity_of_diferent_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_diferent_words = set(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = list(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = len(quantity_of_diferent_words)\n",
    "\n",
    "    return quantity_of_diferent_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para criar textos sem repetição de palavras para ser utilizado na análise exploratória "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_no_repeat_words(text):\n",
    "\n",
    "    text_with_no_repeat_words = text.split(\" \")\n",
    "\n",
    "    text_with_no_repeat_words = [i for i in text_with_no_repeat_words if i!=\"\"]\n",
    "\n",
    "    text_with_no_repeat_words = set(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = list(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = \" \".join(text_with_no_repeat_words)\n",
    "\n",
    "    return text_with_no_repeat_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para o pré-processamento do texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "    collection_text = [ {\"text\" : text}]\n",
    "    text = pd.DataFrame(collection_text)\n",
    "\n",
    "    text['text'] = text['text'].astype('str')\n",
    "    text['text'] = text['text'].str.lower()\n",
    "    text['text'] = text['text'].str.replace('\\n',' ')\n",
    "    text['text'] = text['text'].str.replace('\\r',' ')\n",
    "    text['text'] = text['text'].apply(lambda x: norm('NFKD', x).encode('ascii', 'ignore').decode())\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(nltk_stopwords))\n",
    "    text['text'] = text['text'].str.replace(pat,'')\n",
    "    text = text['text'].values[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções (Extração de Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def create_url(query = \"@globoplay -is:retweet\",until_id=None):\n",
    "    \n",
    "    #query = \"@BBB -is:retweet\"\n",
    "    #\"from:twitterdev -is:retweet\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    \n",
    "    if until_id:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100&until_id={}\".format(\n",
    "            query,until_id\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100\".format(\n",
    "            query\n",
    "        )\n",
    "            \n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def extract_100_tweets(query = \"@BBB -is:retweet\",until_id=None):\n",
    "    bearer_token = BEARER_TOKEN\n",
    "    url = create_url(query,until_id)\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    data_tweets = json.dumps(json_response, indent=4, sort_keys=True)\n",
    "    return json_response\n",
    "\n",
    "def extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",start_from_id=None,query=\"@BBB\"):\n",
    "    \n",
    "    \n",
    "    oldest_id = None\n",
    "    \n",
    "    for i in tqdm(range(qnt_cycle)):\n",
    "    \n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            #extract the 100 tweets first\n",
    "            \n",
    "            if start_from_id:\n",
    "        \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=None)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=start_from_id)\n",
    "                \n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets[\"data\"])\n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            \n",
    "            oldest_id = data_tweets['meta']['oldest_id']\n",
    "            \n",
    "            oldest_date = date_extraction\n",
    "            \n",
    "            df_data_tweets = df_data_tweets_temp.copy()\n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,date_extraction_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file,sep=\",\")\n",
    "            \n",
    "    \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            #extract more 100 tweets older\n",
    "            \n",
    "            data_tweets_temp = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=oldest_id)\n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets_temp[\"data\"])\n",
    "            \n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            oldest_id = data_tweets_temp['meta']['oldest_id']\n",
    "            \n",
    "            df_data_tweets = pd.concat([df_data_tweets,df_data_tweets_temp.copy()])\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets.reset_index(inplace=True,drop=True)\n",
    "            \n",
    "            \n",
    "            # remove old files\n",
    "            \n",
    "            os.remove(name_file)\n",
    "            \n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            oldest_date_str = str(oldest_date).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,oldest_date_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file.format(folder),sep=\",\")\n",
    "            \n",
    "            \n",
    "\n",
    "    return df_data_tweets\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "data_tweets_final = extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",query=\"globoplay\")#,start_from_id=\"1367600965277384706\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1381312014316867587</td>\n",
       "      <td>@Its_Jander @globoplay Uso mas até  que carreg...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1381312000530202624</td>\n",
       "      <td>globoplay pare de nos ameacar eu tenho familia...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1381311982360481797</td>\n",
       "      <td>Passando o documentário da @SandyLeah e do @Ju...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1381311977520250887</td>\n",
       "      <td>@danielrenardi @globoplay Ciranda De Pedra, po...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1381311962852777992</td>\n",
       "      <td>amoo a melhor https://t.co/SQiz8oWCsY</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1381311939092041733</td>\n",
       "      <td>Affff Globoplay me poupe, se poupe, nos poupe ...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1381311934461513730</td>\n",
       "      <td>@SeriesTWBZ avisa que flopou, globoplay decain...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1381311924147732483</td>\n",
       "      <td>A dupla #SandyeJunior foi um fenômeno no Brasi...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1381311914962259971</td>\n",
       "      <td>@beltraomaria @globoplay @axexeo @DiraPaesCom ...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1381311914022670342</td>\n",
       "      <td>Tantos pontos até mesmo técnicos para melhorar...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1381311911162183682</td>\n",
       "      <td>@Fafelayabe @ligadoemserie @rosana @globoplay ...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1381311891344142344</td>\n",
       "      <td>Aguardando ansiosamente https://t.co/nDS30l3GS0</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1381311889595101192</td>\n",
       "      <td>Esse anuncio, todo o espectro dele\\nSimplesmen...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1381311889116962822</td>\n",
       "      <td>ces ja perceberam que no cimena do lider eles ...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1381311834599358468</td>\n",
       "      <td>Assistam no Globoplay \" A corrida das Vacinas\"...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1381311829444558855</td>\n",
       "      <td>@globoplay Jamais 🤢</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1381311829226426375</td>\n",
       "      <td>@globoplay Vem Mamacita</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1381311817260138497</td>\n",
       "      <td>@leilasoares5 Olá @leilasoares5, não se preocu...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1381311806975709185</td>\n",
       "      <td>@globoplay O Doc mais aguardado avisa, Glo 🤫</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1381311801959321605</td>\n",
       "      <td>A @luizatrajano contou no Altas Horas para o @...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1381311797081296898</td>\n",
       "      <td>só não cancelo minha assinatura por causa das ...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1381311788411715584</td>\n",
       "      <td>@jfavss @globoplay Old jotta, lenda ninguém acima</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1381311788201967618</td>\n",
       "      <td>Quem tem @globoplay coloca no programa de 27/0...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1381311765712109580</td>\n",
       "      <td>k https://t.co/TcV4mlODtk</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1381311754312028160</td>\n",
       "      <td>@globoplay o documentário nera aberto a não as...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1381311742236561409</td>\n",
       "      <td>Top1 coisas forçadas que nunca vou entender: \\...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1381311735810957322</td>\n",
       "      <td>Obrigada @globoplay por esse projeto incrível!...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1381311726893817870</td>\n",
       "      <td>Oiii @globoplay nunca te pedi nada.... mas pod...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1381311705418960898</td>\n",
       "      <td>@danlonewolf @globoplay Old</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1381311704999591936</td>\n",
       "      <td>a culpa é grande né rede grobo https://t.co/Sf...</td>\n",
       "      <td>2021-04-11 15:24:03.892362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1381312014316867587  @Its_Jander @globoplay Uso mas até  que carreg...   \n",
       "1   1381312000530202624  globoplay pare de nos ameacar eu tenho familia...   \n",
       "2   1381311982360481797  Passando o documentário da @SandyLeah e do @Ju...   \n",
       "3   1381311977520250887  @danielrenardi @globoplay Ciranda De Pedra, po...   \n",
       "4   1381311962852777992              amoo a melhor https://t.co/SQiz8oWCsY   \n",
       "5   1381311939092041733  Affff Globoplay me poupe, se poupe, nos poupe ...   \n",
       "6   1381311934461513730  @SeriesTWBZ avisa que flopou, globoplay decain...   \n",
       "7   1381311924147732483  A dupla #SandyeJunior foi um fenômeno no Brasi...   \n",
       "8   1381311914962259971  @beltraomaria @globoplay @axexeo @DiraPaesCom ...   \n",
       "9   1381311914022670342  Tantos pontos até mesmo técnicos para melhorar...   \n",
       "10  1381311911162183682  @Fafelayabe @ligadoemserie @rosana @globoplay ...   \n",
       "11  1381311891344142344    Aguardando ansiosamente https://t.co/nDS30l3GS0   \n",
       "12  1381311889595101192  Esse anuncio, todo o espectro dele\\nSimplesmen...   \n",
       "13  1381311889116962822  ces ja perceberam que no cimena do lider eles ...   \n",
       "14  1381311834599358468  Assistam no Globoplay \" A corrida das Vacinas\"...   \n",
       "15  1381311829444558855                                @globoplay Jamais 🤢   \n",
       "16  1381311829226426375                            @globoplay Vem Mamacita   \n",
       "17  1381311817260138497  @leilasoares5 Olá @leilasoares5, não se preocu...   \n",
       "18  1381311806975709185       @globoplay O Doc mais aguardado avisa, Glo 🤫   \n",
       "19  1381311801959321605  A @luizatrajano contou no Altas Horas para o @...   \n",
       "20  1381311797081296898  só não cancelo minha assinatura por causa das ...   \n",
       "21  1381311788411715584  @jfavss @globoplay Old jotta, lenda ninguém acima   \n",
       "22  1381311788201967618  Quem tem @globoplay coloca no programa de 27/0...   \n",
       "23  1381311765712109580                          k https://t.co/TcV4mlODtk   \n",
       "24  1381311754312028160  @globoplay o documentário nera aberto a não as...   \n",
       "25  1381311742236561409  Top1 coisas forçadas que nunca vou entender: \\...   \n",
       "26  1381311735810957322  Obrigada @globoplay por esse projeto incrível!...   \n",
       "27  1381311726893817870  Oiii @globoplay nunca te pedi nada.... mas pod...   \n",
       "28  1381311705418960898                        @danlonewolf @globoplay Old   \n",
       "29  1381311704999591936  a culpa é grande né rede grobo https://t.co/Sf...   \n",
       "\n",
       "              date_extraction  \n",
       "0  2021-04-11 15:24:03.892362  \n",
       "1  2021-04-11 15:24:03.892362  \n",
       "2  2021-04-11 15:24:03.892362  \n",
       "3  2021-04-11 15:24:03.892362  \n",
       "4  2021-04-11 15:24:03.892362  \n",
       "5  2021-04-11 15:24:03.892362  \n",
       "6  2021-04-11 15:24:03.892362  \n",
       "7  2021-04-11 15:24:03.892362  \n",
       "8  2021-04-11 15:24:03.892362  \n",
       "9  2021-04-11 15:24:03.892362  \n",
       "10 2021-04-11 15:24:03.892362  \n",
       "11 2021-04-11 15:24:03.892362  \n",
       "12 2021-04-11 15:24:03.892362  \n",
       "13 2021-04-11 15:24:03.892362  \n",
       "14 2021-04-11 15:24:03.892362  \n",
       "15 2021-04-11 15:24:03.892362  \n",
       "16 2021-04-11 15:24:03.892362  \n",
       "17 2021-04-11 15:24:03.892362  \n",
       "18 2021-04-11 15:24:03.892362  \n",
       "19 2021-04-11 15:24:03.892362  \n",
       "20 2021-04-11 15:24:03.892362  \n",
       "21 2021-04-11 15:24:03.892362  \n",
       "22 2021-04-11 15:24:03.892362  \n",
       "23 2021-04-11 15:24:03.892362  \n",
       "24 2021-04-11 15:24:03.892362  \n",
       "25 2021-04-11 15:24:03.892362  \n",
       "26 2021-04-11 15:24:03.892362  \n",
       "27 2021-04-11 15:24:03.892362  \n",
       "28 2021-04-11 15:24:03.892362  \n",
       "29 2021-04-11 15:24:03.892362  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de uma coluna com os textos sem repetição de palavras para ser utilizado na análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['text_unique_words'] = data_tweets_final['text'].apply(lambda x: convert_text_to_no_repeat_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo Número de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo Número de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_diferent_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_diferent_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_mean = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.824297</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>0.438755</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.438755</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>0.376506</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.329317</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>0.229920</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>0.202811</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.198795</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.176707</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>0.169679</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MEAN      WORDS\n",
       "1495  0.824297  globoplay\n",
       "1586  0.438755      https\n",
       "694   0.438755         co\n",
       "2692  0.376506        que\n",
       "893   0.329317         de\n",
       "2241  0.229920        não\n",
       "2204  0.202811         no\n",
       "1031  0.198795         do\n",
       "867   0.176707         da\n",
       "1222  0.169679         eu"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>821</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>437</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>437</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>375</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>328</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>229</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>202</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>198</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>176</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>169</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUM      WORDS\n",
       "1495  821  globoplay\n",
       "1586  437      https\n",
       "694   437         co\n",
       "2692  375        que\n",
       "893   328         de\n",
       "2241  229        não\n",
       "2204  202         no\n",
       "1031  198         do\n",
       "867   176         da\n",
       "1222  169         eu"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_mean = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.067149</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.051725</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>0.051725</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>0.039750</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.034311</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>0.028884</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>0.026339</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.025269</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>0.024085</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.023721</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MEAN      WORDS\n",
       "1495  0.067149  globoplay\n",
       "694   0.051725         co\n",
       "1586  0.051725      https\n",
       "2692  0.039750        que\n",
       "893   0.034311         de\n",
       "2241  0.028884        não\n",
       "2204  0.026339         no\n",
       "1031  0.025269         do\n",
       "1222  0.024085         eu\n",
       "867   0.023721         da"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_tfidf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MAX TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_max = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MAX',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAX</th>\n",
       "      <th>WORDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.081188</td>\n",
       "      <td>globoplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>0.075134</td>\n",
       "      <td>que</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>0.069778</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>0.069217</td>\n",
       "      <td>https</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>0.069217</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.065540</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>0.065443</td>\n",
       "      <td>eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.063770</td>\n",
       "      <td>mamacita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>0.063082</td>\n",
       "      <td>vou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>0.062834</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MAX      WORDS\n",
       "1495  0.081188  globoplay\n",
       "2692  0.075134        que\n",
       "2241  0.069778        não\n",
       "1586  0.069217      https\n",
       "694   0.069217         co\n",
       "893   0.065540         de\n",
       "1222  0.065443         eu\n",
       "1976  0.063770   mamacita\n",
       "3403  0.063082        vou\n",
       "1031  0.062834         do"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_tfidf_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
