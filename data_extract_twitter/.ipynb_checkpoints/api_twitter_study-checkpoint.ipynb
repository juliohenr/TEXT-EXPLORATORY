{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from api_keys import BEARER_TOKEN\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções (Análise Exploratória)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para plotar bar plot com a contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_count_words(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para plotar bar plot com tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_tf_idf(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    \"MAX\":data_vect.std(axis=0)\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text):\n",
    "\n",
    "    quantity_of_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_words = [i for i in quantity_of_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_words = len(quantity_of_words)\n",
    "\n",
    "    return quantity_of_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para contagem de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_diferent_words(text):\n",
    "\n",
    "    quantity_of_diferent_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_diferent_words = [i for i in quantity_of_diferent_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_diferent_words = set(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = list(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = len(quantity_of_diferent_words)\n",
    "\n",
    "    return quantity_of_diferent_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para criar textos sem repetição de palavras para ser utilizado na análise exploratória "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_no_repeat_words(text):\n",
    "\n",
    "    text_with_no_repeat_words = text.split(\" \")\n",
    "\n",
    "    text_with_no_repeat_words = [i for i in text_with_no_repeat_words if i!=\"\"]\n",
    "\n",
    "    text_with_no_repeat_words = set(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = list(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = \" \".join(text_with_no_repeat_words)\n",
    "\n",
    "    return text_with_no_repeat_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para o pré-processamento do texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "    collection_text = [ {\"text\" : text}]\n",
    "    text = pd.DataFrame(collection_text)\n",
    "\n",
    "    text['text'] = text['text'].astype('str')\n",
    "    text['text'] = text['text'].str.lower()\n",
    "    text['text'] = text['text'].str.replace('\\n',' ')\n",
    "    text['text'] = text['text'].str.replace('\\r',' ')\n",
    "    text['text'] = text['text'].apply(lambda x: norm('NFKD', x).encode('ascii', 'ignore').decode())\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(nltk_stopwords))\n",
    "    text['text'] = text['text'].str.replace(pat,'')\n",
    "    text = text['text'].values[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções (Extração de Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def create_url(query = \"@globoplay -is:retweet\",until_id=None):\n",
    "    \n",
    "    #query = \"@BBB -is:retweet\"\n",
    "    #\"from:twitterdev -is:retweet\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    \n",
    "    if until_id:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100&until_id={}\".format(\n",
    "            query,until_id\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100\".format(\n",
    "            query\n",
    "        )\n",
    "            \n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def extract_100_tweets(query = \"@BBB -is:retweet\",until_id=None):\n",
    "    bearer_token = BEARER_TOKEN\n",
    "    url = create_url(query,until_id)\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    data_tweets = json.dumps(json_response, indent=4, sort_keys=True)\n",
    "    return json_response\n",
    "\n",
    "def extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",start_from_id=None,query=\"@BBB\"):\n",
    "    \n",
    "    \n",
    "    oldest_id = None\n",
    "    \n",
    "    for i in tqdm(range(qnt_cycle)):\n",
    "    \n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            #extract the 100 tweets first\n",
    "            \n",
    "            if start_from_id:\n",
    "        \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=None)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=start_from_id)\n",
    "                \n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets[\"data\"])\n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            \n",
    "            oldest_id = data_tweets['meta']['oldest_id']\n",
    "            \n",
    "            oldest_date = date_extraction\n",
    "            \n",
    "            df_data_tweets = df_data_tweets_temp.copy()\n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,date_extraction_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file,sep=\",\")\n",
    "            \n",
    "    \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            #extract more 100 tweets older\n",
    "            \n",
    "            data_tweets_temp = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=oldest_id)\n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets_temp[\"data\"])\n",
    "            \n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            oldest_id = data_tweets_temp['meta']['oldest_id']\n",
    "            \n",
    "            df_data_tweets = pd.concat([df_data_tweets,df_data_tweets_temp.copy()])\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets.reset_index(inplace=True,drop=True)\n",
    "            \n",
    "            \n",
    "            # remove old files\n",
    "            \n",
    "            os.remove(name_file)\n",
    "            \n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            oldest_date_str = str(oldest_date).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,oldest_date_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file.format(folder),sep=\",\")\n",
    "            \n",
    "            \n",
    "\n",
    "    return df_data_tweets\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "data_tweets_final = extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",query=\"globoplay\")#,start_from_id=\"1367600965277384706\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382485715888566274</td>\n",
       "      <td>GNT To pistola que perdi a novela!!!!!! como a...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1382485694036246533</td>\n",
       "      <td>@allana_lara1 @globoplay Falei pra assinar o P...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1382485540809936898</td>\n",
       "      <td>Tava aqui lutando com o globoplay pra assistir...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1382485532291256323</td>\n",
       "      <td>@rrrrrulia to procurando no globoplay o capitu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1382485509302329344</td>\n",
       "      <td>netflix, prime vídeo, globoplay, disney+ e eu ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382485496140546048</td>\n",
       "      <td>https://t.co/kyZ2a8Kp5w</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1382485467568934912</td>\n",
       "      <td>@PortalTracklist Eu assino Globoplay para assi...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1382485422522122246</td>\n",
       "      <td>Tô dando contas:\\nGLOBOPLAY\\nTELECINE\\nQuem qu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1382485420143951874</td>\n",
       "      <td>alguém de bom coração pra me passar a conta do...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1382485268603809793</td>\n",
       "      <td>globoplay você prometeu</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1382485179961389058</td>\n",
       "      <td>agora parei pra pensar que eu assisto 4 das 5 ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1382485146511761410</td>\n",
       "      <td>@Dantinhas O globoplay tá péssimo esse ano</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1382485127058575363</td>\n",
       "      <td>#LiveVozViolaeViolao  @SergioReis\\n@zcloficial...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1382484914680033286</td>\n",
       "      <td>@globoplay 🙄🙄🙄 https://t.co/MQGBSF26aA</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1382484860921647105</td>\n",
       "      <td>@globoplay Responsa filho retratou muito bem o...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1382484800695590912</td>\n",
       "      <td>Na moral, que série absurdamente incrível! \\n\"...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1382484783264071680</td>\n",
       "      <td>Globoplay não vai fazer um documentário meu nu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1382484777232703491</td>\n",
       "      <td>@KahRk4 @globoplay @TVGlobo JA É SUCESSO !!!</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1382484623486255105</td>\n",
       "      <td>ah vou nem assistir, vejo no globoplay dps</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1382484588107284484</td>\n",
       "      <td>Infos Apimentadas: A Ana Clara gravou para o p...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1382484473581871104</td>\n",
       "      <td>duvido alguém me passar a senha da globoplay s...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1382484338760105984</td>\n",
       "      <td>Alô senhora @globoplay o capítulo de 17/09/15 ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1382484320762335233</td>\n",
       "      <td>@cla_jackson Talvez eu tenha exagerado no russ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1382484297131642881</td>\n",
       "      <td>Se tivesse um gizellyplay eu juro que eu assin...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1382484280765452291</td>\n",
       "      <td>alô @globoplay libera os eps da edição especia...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1382484114025156608</td>\n",
       "      <td>@_loweasy_ Assiste pelo @GloboPlay</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1382483973738221568</td>\n",
       "      <td>pô, n tem nenhum site da globoplay pirata n? t...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1382483881488683008</td>\n",
       "      <td>Esses câmeras não melhoram mesmo né globoplay....</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1382483877273468933</td>\n",
       "      <td>@globoplay Então revejam que decide pois se es...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1382483874115166208</td>\n",
       "      <td>o amigo de meu pai que faz parte da milícia do...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1382485715888566274  GNT To pistola que perdi a novela!!!!!! como a...   \n",
       "1   1382485694036246533  @allana_lara1 @globoplay Falei pra assinar o P...   \n",
       "2   1382485540809936898  Tava aqui lutando com o globoplay pra assistir...   \n",
       "3   1382485532291256323  @rrrrrulia to procurando no globoplay o capitu...   \n",
       "4   1382485509302329344  netflix, prime vídeo, globoplay, disney+ e eu ...   \n",
       "5   1382485496140546048                            https://t.co/kyZ2a8Kp5w   \n",
       "6   1382485467568934912  @PortalTracklist Eu assino Globoplay para assi...   \n",
       "7   1382485422522122246  Tô dando contas:\\nGLOBOPLAY\\nTELECINE\\nQuem qu...   \n",
       "8   1382485420143951874  alguém de bom coração pra me passar a conta do...   \n",
       "9   1382485268603809793                            globoplay você prometeu   \n",
       "10  1382485179961389058  agora parei pra pensar que eu assisto 4 das 5 ...   \n",
       "11  1382485146511761410         @Dantinhas O globoplay tá péssimo esse ano   \n",
       "12  1382485127058575363  #LiveVozViolaeViolao  @SergioReis\\n@zcloficial...   \n",
       "13  1382484914680033286             @globoplay 🙄🙄🙄 https://t.co/MQGBSF26aA   \n",
       "14  1382484860921647105  @globoplay Responsa filho retratou muito bem o...   \n",
       "15  1382484800695590912  Na moral, que série absurdamente incrível! \\n\"...   \n",
       "16  1382484783264071680  Globoplay não vai fazer um documentário meu nu...   \n",
       "17  1382484777232703491       @KahRk4 @globoplay @TVGlobo JA É SUCESSO !!!   \n",
       "18  1382484623486255105         ah vou nem assistir, vejo no globoplay dps   \n",
       "19  1382484588107284484  Infos Apimentadas: A Ana Clara gravou para o p...   \n",
       "20  1382484473581871104  duvido alguém me passar a senha da globoplay s...   \n",
       "21  1382484338760105984  Alô senhora @globoplay o capítulo de 17/09/15 ...   \n",
       "22  1382484320762335233  @cla_jackson Talvez eu tenha exagerado no russ...   \n",
       "23  1382484297131642881  Se tivesse um gizellyplay eu juro que eu assin...   \n",
       "24  1382484280765452291  alô @globoplay libera os eps da edição especia...   \n",
       "25  1382484114025156608                 @_loweasy_ Assiste pelo @GloboPlay   \n",
       "26  1382483973738221568  pô, n tem nenhum site da globoplay pirata n? t...   \n",
       "27  1382483881488683008  Esses câmeras não melhoram mesmo né globoplay....   \n",
       "28  1382483877273468933  @globoplay Então revejam que decide pois se es...   \n",
       "29  1382483874115166208  o amigo de meu pai que faz parte da milícia do...   \n",
       "\n",
       "              date_extraction  \n",
       "0  2021-04-14 21:08:04.180408  \n",
       "1  2021-04-14 21:08:04.180408  \n",
       "2  2021-04-14 21:08:04.180408  \n",
       "3  2021-04-14 21:08:04.180408  \n",
       "4  2021-04-14 21:08:04.180408  \n",
       "5  2021-04-14 21:08:04.180408  \n",
       "6  2021-04-14 21:08:04.180408  \n",
       "7  2021-04-14 21:08:04.180408  \n",
       "8  2021-04-14 21:08:04.180408  \n",
       "9  2021-04-14 21:08:04.180408  \n",
       "10 2021-04-14 21:08:04.180408  \n",
       "11 2021-04-14 21:08:04.180408  \n",
       "12 2021-04-14 21:08:04.180408  \n",
       "13 2021-04-14 21:08:04.180408  \n",
       "14 2021-04-14 21:08:04.180408  \n",
       "15 2021-04-14 21:08:04.180408  \n",
       "16 2021-04-14 21:08:04.180408  \n",
       "17 2021-04-14 21:08:04.180408  \n",
       "18 2021-04-14 21:08:04.180408  \n",
       "19 2021-04-14 21:08:04.180408  \n",
       "20 2021-04-14 21:08:04.180408  \n",
       "21 2021-04-14 21:08:04.180408  \n",
       "22 2021-04-14 21:08:04.180408  \n",
       "23 2021-04-14 21:08:04.180408  \n",
       "24 2021-04-14 21:08:04.180408  \n",
       "25 2021-04-14 21:08:04.180408  \n",
       "26 2021-04-14 21:08:04.180408  \n",
       "27 2021-04-14 21:08:04.180408  \n",
       "28 2021-04-14 21:08:04.180408  \n",
       "29 2021-04-14 21:08:04.180408  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date_extraction</th>\n",
       "      <th>text_unique_words</th>\n",
       "      <th>number_tokens</th>\n",
       "      <th>number_diferent_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382485715888566274</td>\n",
       "      <td>GNT To pistola que perdi a novela!!!!!! como a...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>achando n globoplay? pistola perdi que novela!...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1382485694036246533</td>\n",
       "      <td>@allana_lara1 @globoplay Falei pra assinar o P...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>Prime @allana_lara1 pra o vídeo @globoplay Fal...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1382485540809936898</td>\n",
       "      <td>Tava aqui lutando com o globoplay pra assistir...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>de Tava o pra achando aqui hoje quinta... fase...</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1382485532291256323</td>\n",
       "      <td>@rrrrrulia to procurando no globoplay o capitu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>hj procurando de e o globoplay n achando!!!!! ...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1382485509302329344</td>\n",
       "      <td>netflix, prime vídeo, globoplay, disney+ e eu ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>xvideos prime e o queria netflix, globoplay, f...</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1382418258876370956</td>\n",
       "      <td>@FsPFeVC @magavassidiaz Só na globoplay no mom...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>@FsPFeVC Só na globoplay @magavassidiaz moment...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1382418211723968514</td>\n",
       "      <td>Titchela já divulgou o #CasaKalimanm e vcs? ❤️...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>divulgou ❤️\\n\\nDia Titchela e o 28/04 já @glob...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1382418206061694984</td>\n",
       "      <td>assisti esse umas 30x e sempre passo mal\\n htt...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>passo https://t.co/Oug4PRKAY6 e sempre assisti...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1382418192161722377</td>\n",
       "      <td>Passou, floodou\\nReprodução: @globoplay @TVGlo...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>Passou, @TVGlobo\\n\\nhttps://t.co/Jer1OzNrO0 fl...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>1382418136910204928</td>\n",
       "      <td>te amo globoplay</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>te amo globoplay</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0    1382485715888566274  GNT To pistola que perdi a novela!!!!!! como a...   \n",
       "1    1382485694036246533  @allana_lara1 @globoplay Falei pra assinar o P...   \n",
       "2    1382485540809936898  Tava aqui lutando com o globoplay pra assistir...   \n",
       "3    1382485532291256323  @rrrrrulia to procurando no globoplay o capitu...   \n",
       "4    1382485509302329344  netflix, prime vídeo, globoplay, disney+ e eu ...   \n",
       "..                   ...                                                ...   \n",
       "990  1382418258876370956  @FsPFeVC @magavassidiaz Só na globoplay no mom...   \n",
       "991  1382418211723968514  Titchela já divulgou o #CasaKalimanm e vcs? ❤️...   \n",
       "992  1382418206061694984  assisti esse umas 30x e sempre passo mal\\n htt...   \n",
       "993  1382418192161722377  Passou, floodou\\nReprodução: @globoplay @TVGlo...   \n",
       "994  1382418136910204928                                   te amo globoplay   \n",
       "\n",
       "               date_extraction  \\\n",
       "0   2021-04-14 21:08:04.180408   \n",
       "1   2021-04-14 21:08:04.180408   \n",
       "2   2021-04-14 21:08:04.180408   \n",
       "3   2021-04-14 21:08:04.180408   \n",
       "4   2021-04-14 21:08:04.180408   \n",
       "..                         ...   \n",
       "990 2021-04-14 21:08:13.938277   \n",
       "991 2021-04-14 21:08:13.938277   \n",
       "992 2021-04-14 21:08:13.938277   \n",
       "993 2021-04-14 21:08:13.938277   \n",
       "994 2021-04-14 21:08:13.938277   \n",
       "\n",
       "                                     text_unique_words  number_tokens  \\\n",
       "0    achando n globoplay? pistola perdi que novela!...             20   \n",
       "1    Prime @allana_lara1 pra o vídeo @globoplay Fal...              8   \n",
       "2    de Tava o pra achando aqui hoje quinta... fase...             19   \n",
       "3    hj procurando de e o globoplay n achando!!!!! ...             13   \n",
       "4    xvideos prime e o queria netflix, globoplay, f...             18   \n",
       "..                                                 ...            ...   \n",
       "990  @FsPFeVC Só na globoplay @magavassidiaz moment...              7   \n",
       "991  divulgou ❤️\\n\\nDia Titchela e o 28/04 já @glob...             14   \n",
       "992  passo https://t.co/Oug4PRKAY6 e sempre assisti...              9   \n",
       "993  Passou, @TVGlobo\\n\\nhttps://t.co/Jer1OzNrO0 fl...              4   \n",
       "994                                   te amo globoplay              3   \n",
       "\n",
       "     number_diferent_tokens  \n",
       "0                        20  \n",
       "1                         8  \n",
       "2                        17  \n",
       "3                        12  \n",
       "4                        17  \n",
       "..                      ...  \n",
       "990                       7  \n",
       "991                      14  \n",
       "992                       9  \n",
       "993                       4  \n",
       "994                       3  \n",
       "\n",
       "[995 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 1.25, 2.5 , 3.75, 5.  ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "1\n",
      "1.25\n",
      "2\n",
      "2.5\n",
      "[2.5,3.8)\n",
      "3\n",
      "3.75\n",
      "4\n",
      "5.0\n",
      "erro\n"
     ]
    }
   ],
   "source": [
    "def function_to_calc_histogram(initial_interval, final_interval,n_bins,x):\n",
    "\n",
    "    interval = np.linspace(initial_interval, final_interval, num=n_bins)\n",
    "\n",
    "    for j,i in enumerate(interval):\n",
    "\n",
    "\n",
    "        if i == interval[len(interval)-1]:\n",
    "\n",
    "            if x>=i:\n",
    "\n",
    "                print(\"{}<\".format(x))\n",
    "\n",
    "                return \"{}<\".format(x)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            if x>=i and x<interval[j+1]:\n",
    "\n",
    "                inicial = round(i, 1)\n",
    "\n",
    "                final = round(interval[j+1],1)\n",
    "\n",
    "                print(\"[{},{})\".format(inicial,final))\n",
    "\n",
    "                return \"[{},{})\".format(inicial,final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação de uma coluna com os textos sem repetição de palavras para ser utilizado na análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['text_unique_words'] = data_tweets_final['text'].apply(lambda x: convert_text_to_no_repeat_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo Número de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo Número de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_diferent_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_diferent_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_mean = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9758793969849247,\n",
       " 0.3829145728643216,\n",
       " 0.3829145728643216,\n",
       " 0.33768844221105526,\n",
       " 0.3035175879396985,\n",
       " 0.23919597989949748,\n",
       " 0.18592964824120603,\n",
       " 0.1829145728643216,\n",
       " 0.16683417085427135,\n",
       " 0.1527638190954774]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"MEAN\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['globoplay', 'https', 'co', 'que', 'de', 'no', 'da', 'eu', 'não', 'do']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"WORDS\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum = plot_bar_count_words(text_column='text_unique_words',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum[\"P_DOCS\"] =  df_report_sum[\"SUM\"]/len(data_tweets_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM</th>\n",
       "      <th>WORDS</th>\n",
       "      <th>P_DOCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>950</td>\n",
       "      <td>globoplay</td>\n",
       "      <td>0.954774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>380</td>\n",
       "      <td>co</td>\n",
       "      <td>0.381910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>380</td>\n",
       "      <td>https</td>\n",
       "      <td>0.381910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>258</td>\n",
       "      <td>que</td>\n",
       "      <td>0.259296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>252</td>\n",
       "      <td>de</td>\n",
       "      <td>0.253266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>213</td>\n",
       "      <td>no</td>\n",
       "      <td>0.214070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>158</td>\n",
       "      <td>da</td>\n",
       "      <td>0.158794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>153</td>\n",
       "      <td>eu</td>\n",
       "      <td>0.153769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>143</td>\n",
       "      <td>não</td>\n",
       "      <td>0.143719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>135</td>\n",
       "      <td>na</td>\n",
       "      <td>0.135678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUM      WORDS    P_DOCS\n",
       "1641  950  globoplay  0.954774\n",
       "841   380         co  0.381910\n",
       "1742  380      https  0.381910\n",
       "2830  258        que  0.259296\n",
       "1031  252         de  0.253266\n",
       "2333  213         no  0.214070\n",
       "1006  158         da  0.158794\n",
       "1382  153         eu  0.153769\n",
       "2375  143        não  0.143719\n",
       "2290  135         na  0.135678"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_mean = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MAX TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_max = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MAX',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
