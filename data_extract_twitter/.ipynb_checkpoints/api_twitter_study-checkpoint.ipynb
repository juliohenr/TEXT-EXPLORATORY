{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from api_keys import BEARER_TOKEN\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun√ß√µes (An√°lise Explorat√≥ria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para plotar bar plot com a contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_count_words(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para plotar bar plot com tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_tf_idf(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names(),\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    \"MAX\":data_vect.std(axis=0)\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para contagem de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text):\n",
    "\n",
    "    quantity_of_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_words = [i for i in quantity_of_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_words = len(quantity_of_words)\n",
    "\n",
    "    return quantity_of_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para contagem de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_diferent_words(text):\n",
    "\n",
    "    quantity_of_diferent_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_diferent_words = [i for i in quantity_of_diferent_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_diferent_words = set(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = list(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = len(quantity_of_diferent_words)\n",
    "\n",
    "    return quantity_of_diferent_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para criar textos sem repeti√ß√£o de palavras para ser utilizado na an√°lise explorat√≥ria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_no_repeat_words(text):\n",
    "\n",
    "    text_with_no_repeat_words = text.split(\" \")\n",
    "\n",
    "    text_with_no_repeat_words = [i for i in text_with_no_repeat_words if i!=\"\"]\n",
    "\n",
    "    text_with_no_repeat_words = set(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = list(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = \" \".join(text_with_no_repeat_words)\n",
    "\n",
    "    return text_with_no_repeat_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o para o pr√©-processamento do texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "    collection_text = [ {\"text\" : text}]\n",
    "    text = pd.DataFrame(collection_text)\n",
    "\n",
    "    text['text'] = text['text'].astype('str')\n",
    "    text['text'] = text['text'].str.lower()\n",
    "    text['text'] = text['text'].str.replace('\\n',' ')\n",
    "    text['text'] = text['text'].str.replace('\\r',' ')\n",
    "    text['text'] = text['text'].apply(lambda x: norm('NFKD', x).encode('ascii', 'ignore').decode())\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(nltk_stopwords))\n",
    "    text['text'] = text['text'].str.replace(pat,'')\n",
    "    text = text['text'].values[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun√ß√µes (Extra√ß√£o de Tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "\n",
    "\n",
    "def create_url(query = \"@globoplay -is:retweet\",until_id=None):\n",
    "    \n",
    "    #query = \"@BBB -is:retweet\"\n",
    "    #\"from:twitterdev -is:retweet\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    \n",
    "    if until_id:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100&until_id={}\".format(\n",
    "            query,until_id\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&max_results=100\".format(\n",
    "            query\n",
    "        )\n",
    "            \n",
    "    return url\n",
    "\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def extract_100_tweets(query = \"@BBB -is:retweet\",until_id=None):\n",
    "    bearer_token = BEARER_TOKEN\n",
    "    url = create_url(query,until_id)\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    data_tweets = json.dumps(json_response, indent=4, sort_keys=True)\n",
    "    return json_response\n",
    "\n",
    "def extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",start_from_id=None,query=\"@BBB\"):\n",
    "    \n",
    "    \n",
    "    oldest_id = None\n",
    "    \n",
    "    for i in tqdm(range(qnt_cycle)):\n",
    "    \n",
    "        \n",
    "        if i == 0:\n",
    "            \n",
    "            #extract the 100 tweets first\n",
    "            \n",
    "            if start_from_id:\n",
    "        \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=None)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                data_tweets = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=start_from_id)\n",
    "                \n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets[\"data\"])\n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            \n",
    "            oldest_id = data_tweets['meta']['oldest_id']\n",
    "            \n",
    "            oldest_date = date_extraction\n",
    "            \n",
    "            df_data_tweets = df_data_tweets_temp.copy()\n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,date_extraction_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file,sep=\",\")\n",
    "            \n",
    "    \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            #extract more 100 tweets older\n",
    "            \n",
    "            data_tweets_temp = extract_100_tweets(query = \"{} -is:retweet\".format(query),until_id=oldest_id)\n",
    "            \n",
    "            df_data_tweets_temp = pd.DataFrame(data_tweets_temp[\"data\"])\n",
    "            \n",
    "            \n",
    "            #get the current date\n",
    "            \n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets_temp[\"date_extraction\"] = date_extraction \n",
    "            \n",
    "            oldest_id = data_tweets_temp['meta']['oldest_id']\n",
    "            \n",
    "            df_data_tweets = pd.concat([df_data_tweets,df_data_tweets_temp.copy()])\n",
    "            \n",
    "            date_extraction = datetime.now()\n",
    "            \n",
    "            df_data_tweets.reset_index(inplace=True,drop=True)\n",
    "            \n",
    "            \n",
    "            # remove old files\n",
    "            \n",
    "            os.remove(name_file)\n",
    "            \n",
    "            \n",
    "            # name file\n",
    "            \n",
    "            oldest_date_str = str(oldest_date).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            date_extraction_str = str(date_extraction).replace(\".\",\"-\").replace(\":\",\"-\").replace(\" \",\"-\")\n",
    "            \n",
    "            \n",
    "            name_file = \"./{}/persist_tweets_{}_{}.csv\".format(folder,oldest_date_str,date_extraction_str)\n",
    "            \n",
    "            # persist base\n",
    "            \n",
    "            df_data_tweets.to_csv(name_file.format(folder),sep=\",\")\n",
    "            \n",
    "            \n",
    "\n",
    "    return df_data_tweets\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra√ß√£o de Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "data_tweets_final = extract_many_tweets(qnt_cycle=10,folder=\"data_tweets\",query=\"globoplay\")#,start_from_id=\"1367600965277384706\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date_extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382485715888566274</td>\n",
       "      <td>GNT To pistola que perdi a novela!!!!!! como a...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1382485694036246533</td>\n",
       "      <td>@allana_lara1 @globoplay Falei pra assinar o P...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1382485540809936898</td>\n",
       "      <td>Tava aqui lutando com o globoplay pra assistir...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1382485532291256323</td>\n",
       "      <td>@rrrrrulia to procurando no globoplay o capitu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1382485509302329344</td>\n",
       "      <td>netflix, prime v√≠deo, globoplay, disney+ e eu ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382485496140546048</td>\n",
       "      <td>https://t.co/kyZ2a8Kp5w</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1382485467568934912</td>\n",
       "      <td>@PortalTracklist Eu assino Globoplay para assi...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1382485422522122246</td>\n",
       "      <td>T√¥ dando contas:\\nGLOBOPLAY\\nTELECINE\\nQuem qu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1382485420143951874</td>\n",
       "      <td>algu√©m de bom cora√ß√£o pra me passar a conta do...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1382485268603809793</td>\n",
       "      <td>globoplay voc√™ prometeu</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1382485179961389058</td>\n",
       "      <td>agora parei pra pensar que eu assisto 4 das 5 ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1382485146511761410</td>\n",
       "      <td>@Dantinhas O globoplay t√° p√©ssimo esse ano</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1382485127058575363</td>\n",
       "      <td>#LiveVozViolaeViolao  @SergioReis\\n@zcloficial...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1382484914680033286</td>\n",
       "      <td>@globoplay üôÑüôÑüôÑ https://t.co/MQGBSF26aA</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1382484860921647105</td>\n",
       "      <td>@globoplay Responsa filho retratou muito bem o...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1382484800695590912</td>\n",
       "      <td>Na moral, que s√©rie absurdamente incr√≠vel! \\n\"...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1382484783264071680</td>\n",
       "      <td>Globoplay n√£o vai fazer um document√°rio meu nu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1382484777232703491</td>\n",
       "      <td>@KahRk4 @globoplay @TVGlobo JA √â SUCESSO !!!</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1382484623486255105</td>\n",
       "      <td>ah vou nem assistir, vejo no globoplay dps</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1382484588107284484</td>\n",
       "      <td>Infos Apimentadas: A Ana Clara gravou para o p...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1382484473581871104</td>\n",
       "      <td>duvido algu√©m me passar a senha da globoplay s...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1382484338760105984</td>\n",
       "      <td>Al√¥ senhora @globoplay o cap√≠tulo de 17/09/15 ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1382484320762335233</td>\n",
       "      <td>@cla_jackson Talvez eu tenha exagerado no russ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1382484297131642881</td>\n",
       "      <td>Se tivesse um gizellyplay eu juro que eu assin...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1382484280765452291</td>\n",
       "      <td>al√¥ @globoplay libera os eps da edi√ß√£o especia...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1382484114025156608</td>\n",
       "      <td>@_loweasy_ Assiste pelo @GloboPlay</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1382483973738221568</td>\n",
       "      <td>p√¥, n tem nenhum site da globoplay pirata n? t...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1382483881488683008</td>\n",
       "      <td>Esses c√¢meras n√£o melhoram mesmo n√© globoplay....</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1382483877273468933</td>\n",
       "      <td>@globoplay Ent√£o revejam que decide pois se es...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1382483874115166208</td>\n",
       "      <td>o amigo de meu pai que faz parte da mil√≠cia do...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "0   1382485715888566274  GNT To pistola que perdi a novela!!!!!! como a...   \n",
       "1   1382485694036246533  @allana_lara1 @globoplay Falei pra assinar o P...   \n",
       "2   1382485540809936898  Tava aqui lutando com o globoplay pra assistir...   \n",
       "3   1382485532291256323  @rrrrrulia to procurando no globoplay o capitu...   \n",
       "4   1382485509302329344  netflix, prime v√≠deo, globoplay, disney+ e eu ...   \n",
       "5   1382485496140546048                            https://t.co/kyZ2a8Kp5w   \n",
       "6   1382485467568934912  @PortalTracklist Eu assino Globoplay para assi...   \n",
       "7   1382485422522122246  T√¥ dando contas:\\nGLOBOPLAY\\nTELECINE\\nQuem qu...   \n",
       "8   1382485420143951874  algu√©m de bom cora√ß√£o pra me passar a conta do...   \n",
       "9   1382485268603809793                            globoplay voc√™ prometeu   \n",
       "10  1382485179961389058  agora parei pra pensar que eu assisto 4 das 5 ...   \n",
       "11  1382485146511761410         @Dantinhas O globoplay t√° p√©ssimo esse ano   \n",
       "12  1382485127058575363  #LiveVozViolaeViolao  @SergioReis\\n@zcloficial...   \n",
       "13  1382484914680033286             @globoplay üôÑüôÑüôÑ https://t.co/MQGBSF26aA   \n",
       "14  1382484860921647105  @globoplay Responsa filho retratou muito bem o...   \n",
       "15  1382484800695590912  Na moral, que s√©rie absurdamente incr√≠vel! \\n\"...   \n",
       "16  1382484783264071680  Globoplay n√£o vai fazer um document√°rio meu nu...   \n",
       "17  1382484777232703491       @KahRk4 @globoplay @TVGlobo JA √â SUCESSO !!!   \n",
       "18  1382484623486255105         ah vou nem assistir, vejo no globoplay dps   \n",
       "19  1382484588107284484  Infos Apimentadas: A Ana Clara gravou para o p...   \n",
       "20  1382484473581871104  duvido algu√©m me passar a senha da globoplay s...   \n",
       "21  1382484338760105984  Al√¥ senhora @globoplay o cap√≠tulo de 17/09/15 ...   \n",
       "22  1382484320762335233  @cla_jackson Talvez eu tenha exagerado no russ...   \n",
       "23  1382484297131642881  Se tivesse um gizellyplay eu juro que eu assin...   \n",
       "24  1382484280765452291  al√¥ @globoplay libera os eps da edi√ß√£o especia...   \n",
       "25  1382484114025156608                 @_loweasy_ Assiste pelo @GloboPlay   \n",
       "26  1382483973738221568  p√¥, n tem nenhum site da globoplay pirata n? t...   \n",
       "27  1382483881488683008  Esses c√¢meras n√£o melhoram mesmo n√© globoplay....   \n",
       "28  1382483877273468933  @globoplay Ent√£o revejam que decide pois se es...   \n",
       "29  1382483874115166208  o amigo de meu pai que faz parte da mil√≠cia do...   \n",
       "\n",
       "              date_extraction  \n",
       "0  2021-04-14 21:08:04.180408  \n",
       "1  2021-04-14 21:08:04.180408  \n",
       "2  2021-04-14 21:08:04.180408  \n",
       "3  2021-04-14 21:08:04.180408  \n",
       "4  2021-04-14 21:08:04.180408  \n",
       "5  2021-04-14 21:08:04.180408  \n",
       "6  2021-04-14 21:08:04.180408  \n",
       "7  2021-04-14 21:08:04.180408  \n",
       "8  2021-04-14 21:08:04.180408  \n",
       "9  2021-04-14 21:08:04.180408  \n",
       "10 2021-04-14 21:08:04.180408  \n",
       "11 2021-04-14 21:08:04.180408  \n",
       "12 2021-04-14 21:08:04.180408  \n",
       "13 2021-04-14 21:08:04.180408  \n",
       "14 2021-04-14 21:08:04.180408  \n",
       "15 2021-04-14 21:08:04.180408  \n",
       "16 2021-04-14 21:08:04.180408  \n",
       "17 2021-04-14 21:08:04.180408  \n",
       "18 2021-04-14 21:08:04.180408  \n",
       "19 2021-04-14 21:08:04.180408  \n",
       "20 2021-04-14 21:08:04.180408  \n",
       "21 2021-04-14 21:08:04.180408  \n",
       "22 2021-04-14 21:08:04.180408  \n",
       "23 2021-04-14 21:08:04.180408  \n",
       "24 2021-04-14 21:08:04.180408  \n",
       "25 2021-04-14 21:08:04.180408  \n",
       "26 2021-04-14 21:08:04.180408  \n",
       "27 2021-04-14 21:08:04.180408  \n",
       "28 2021-04-14 21:08:04.180408  \n",
       "29 2021-04-14 21:08:04.180408  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date_extraction</th>\n",
       "      <th>text_unique_words</th>\n",
       "      <th>number_tokens</th>\n",
       "      <th>number_diferent_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1382485715888566274</td>\n",
       "      <td>GNT To pistola que perdi a novela!!!!!! como a...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>achando n globoplay? pistola perdi que novela!...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1382485694036246533</td>\n",
       "      <td>@allana_lara1 @globoplay Falei pra assinar o P...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>Prime @allana_lara1 pra o v√≠deo @globoplay Fal...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1382485540809936898</td>\n",
       "      <td>Tava aqui lutando com o globoplay pra assistir...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>de Tava o pra achando aqui hoje quinta... fase...</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1382485532291256323</td>\n",
       "      <td>@rrrrrulia to procurando no globoplay o capitu...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>hj procurando de e o globoplay n achando!!!!! ...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1382485509302329344</td>\n",
       "      <td>netflix, prime v√≠deo, globoplay, disney+ e eu ...</td>\n",
       "      <td>2021-04-14 21:08:04.180408</td>\n",
       "      <td>xvideos prime e o queria netflix, globoplay, f...</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>1382418258876370956</td>\n",
       "      <td>@FsPFeVC @magavassidiaz S√≥ na globoplay no mom...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>@FsPFeVC S√≥ na globoplay @magavassidiaz moment...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>1382418211723968514</td>\n",
       "      <td>Titchela j√° divulgou o #CasaKalimanm e vcs? ‚ù§Ô∏è...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>divulgou ‚ù§Ô∏è\\n\\nDia Titchela e o 28/04 j√° @glob...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1382418206061694984</td>\n",
       "      <td>assisti esse umas 30x e sempre passo mal\\n htt...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>passo https://t.co/Oug4PRKAY6 e sempre assisti...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>1382418192161722377</td>\n",
       "      <td>Passou, floodou\\nReprodu√ß√£o: @globoplay @TVGlo...</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>Passou, @TVGlobo\\n\\nhttps://t.co/Jer1OzNrO0 fl...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>1382418136910204928</td>\n",
       "      <td>te amo globoplay</td>\n",
       "      <td>2021-04-14 21:08:13.938277</td>\n",
       "      <td>te amo globoplay</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0    1382485715888566274  GNT To pistola que perdi a novela!!!!!! como a...   \n",
       "1    1382485694036246533  @allana_lara1 @globoplay Falei pra assinar o P...   \n",
       "2    1382485540809936898  Tava aqui lutando com o globoplay pra assistir...   \n",
       "3    1382485532291256323  @rrrrrulia to procurando no globoplay o capitu...   \n",
       "4    1382485509302329344  netflix, prime v√≠deo, globoplay, disney+ e eu ...   \n",
       "..                   ...                                                ...   \n",
       "990  1382418258876370956  @FsPFeVC @magavassidiaz S√≥ na globoplay no mom...   \n",
       "991  1382418211723968514  Titchela j√° divulgou o #CasaKalimanm e vcs? ‚ù§Ô∏è...   \n",
       "992  1382418206061694984  assisti esse umas 30x e sempre passo mal\\n htt...   \n",
       "993  1382418192161722377  Passou, floodou\\nReprodu√ß√£o: @globoplay @TVGlo...   \n",
       "994  1382418136910204928                                   te amo globoplay   \n",
       "\n",
       "               date_extraction  \\\n",
       "0   2021-04-14 21:08:04.180408   \n",
       "1   2021-04-14 21:08:04.180408   \n",
       "2   2021-04-14 21:08:04.180408   \n",
       "3   2021-04-14 21:08:04.180408   \n",
       "4   2021-04-14 21:08:04.180408   \n",
       "..                         ...   \n",
       "990 2021-04-14 21:08:13.938277   \n",
       "991 2021-04-14 21:08:13.938277   \n",
       "992 2021-04-14 21:08:13.938277   \n",
       "993 2021-04-14 21:08:13.938277   \n",
       "994 2021-04-14 21:08:13.938277   \n",
       "\n",
       "                                     text_unique_words  number_tokens  \\\n",
       "0    achando n globoplay? pistola perdi que novela!...             20   \n",
       "1    Prime @allana_lara1 pra o v√≠deo @globoplay Fal...              8   \n",
       "2    de Tava o pra achando aqui hoje quinta... fase...             19   \n",
       "3    hj procurando de e o globoplay n achando!!!!! ...             13   \n",
       "4    xvideos prime e o queria netflix, globoplay, f...             18   \n",
       "..                                                 ...            ...   \n",
       "990  @FsPFeVC S√≥ na globoplay @magavassidiaz moment...              7   \n",
       "991  divulgou ‚ù§Ô∏è\\n\\nDia Titchela e o 28/04 j√° @glob...             14   \n",
       "992  passo https://t.co/Oug4PRKAY6 e sempre assisti...              9   \n",
       "993  Passou, @TVGlobo\\n\\nhttps://t.co/Jer1OzNrO0 fl...              4   \n",
       "994                                   te amo globoplay              3   \n",
       "\n",
       "     number_diferent_tokens  \n",
       "0                        20  \n",
       "1                         8  \n",
       "2                        17  \n",
       "3                        12  \n",
       "4                        17  \n",
       "..                      ...  \n",
       "990                       7  \n",
       "991                      14  \n",
       "992                       9  \n",
       "993                       4  \n",
       "994                       3  \n",
       "\n",
       "[995 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tweets_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 1.25, 2.5 , 3.75, 5.  ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "1\n",
      "1.25\n",
      "2\n",
      "2.5\n",
      "[2.5,3.8)\n",
      "3\n",
      "3.75\n",
      "4\n",
      "5.0\n",
      "erro\n"
     ]
    }
   ],
   "source": [
    "def function_to_calc_histogram(initial_interval, final_interval,n_bins,x):\n",
    "\n",
    "    interval = np.linspace(initial_interval, final_interval, num=n_bins)\n",
    "\n",
    "    for j,i in enumerate(interval):\n",
    "\n",
    "\n",
    "        if i == interval[len(interval)-1]:\n",
    "\n",
    "            if x>=i:\n",
    "\n",
    "                print(\"{}<\".format(x))\n",
    "\n",
    "                return \"{}<\".format(x)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            if x>=i and x<interval[j+1]:\n",
    "\n",
    "                inicial = round(i, 1)\n",
    "\n",
    "                final = round(interval[j+1],1)\n",
    "\n",
    "                print(\"[{},{})\".format(inicial,final))\n",
    "\n",
    "                return \"[{},{})\".format(inicial,final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria√ß√£o de uma coluna com os textos sem repeti√ß√£o de palavras para ser utilizado na an√°lise explorat√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['text_unique_words'] = data_tweets_final['text'].apply(lambda x: convert_text_to_no_repeat_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo N√∫mero de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculo N√∫mero de diferentes tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tweets_final['number_diferent_tokens'] = data_tweets_final['text'].apply(lambda x: calculate_number_diferent_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_mean = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9758793969849247,\n",
       " 0.3829145728643216,\n",
       " 0.3829145728643216,\n",
       " 0.33768844221105526,\n",
       " 0.3035175879396985,\n",
       " 0.23919597989949748,\n",
       " 0.18592964824120603,\n",
       " 0.1829145728643216,\n",
       " 0.16683417085427135,\n",
       " 0.1527638190954774]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"MEAN\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['globoplay', 'https', 'co', 'que', 'de', 'no', 'da', 'eu', 'n√£o', 'do']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_mean[\"WORDS\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum = plot_bar_count_words(text_column='text_unique_words',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum[\"P_DOCS\"] =  df_report_sum[\"SUM\"]/len(data_tweets_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUM</th>\n",
       "      <th>WORDS</th>\n",
       "      <th>P_DOCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>950</td>\n",
       "      <td>globoplay</td>\n",
       "      <td>0.954774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>380</td>\n",
       "      <td>co</td>\n",
       "      <td>0.381910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>380</td>\n",
       "      <td>https</td>\n",
       "      <td>0.381910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>258</td>\n",
       "      <td>que</td>\n",
       "      <td>0.259296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>252</td>\n",
       "      <td>de</td>\n",
       "      <td>0.253266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>213</td>\n",
       "      <td>no</td>\n",
       "      <td>0.214070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>158</td>\n",
       "      <td>da</td>\n",
       "      <td>0.158794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>153</td>\n",
       "      <td>eu</td>\n",
       "      <td>0.153769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>143</td>\n",
       "      <td>n√£o</td>\n",
       "      <td>0.143719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>135</td>\n",
       "      <td>na</td>\n",
       "      <td>0.135678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUM      WORDS    P_DOCS\n",
       "1641  950  globoplay  0.954774\n",
       "841   380         co  0.381910\n",
       "1742  380      https  0.381910\n",
       "2830  258        que  0.259296\n",
       "1031  252         de  0.253266\n",
       "2333  213         no  0.214070\n",
       "1006  158         da  0.158794\n",
       "1382  153         eu  0.153769\n",
       "2375  143        n√£o  0.143719\n",
       "2290  135         na  0.135678"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs = plot_bar_count_words(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MEAN TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_mean = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MEAN',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF top 10 MAX TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_max = plot_bar_tf_idf(text_column='text',\n",
    "                                                dataframe=data_tweets_final,\n",
    "                                                metric='MAX',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_tfidf_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
